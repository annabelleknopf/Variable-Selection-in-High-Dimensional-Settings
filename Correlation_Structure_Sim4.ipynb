{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df3d262b-fc74-430d-9f84-16b8c309f895",
   "metadata": {},
   "source": [
    "# Correlation Structure of Data Set Simulation4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c263f627-e282-466c-8c32-3cedaec264c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from time import time\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng, Generator\n",
    "from scipy.special import expit as sigmoid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import scale\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "\n",
    "# Load SNP data\n",
    "r_data_path = os.path.join(\"Data\", \"SNP_data.RData\")\n",
    "if not os.path.exists(r_data_path):\n",
    "    raise FileNotFoundError(f\"{r_data_path} not found – please provide the file.\")\n",
    "\n",
    "r_objects = pyreadr.read_r(r_data_path)\n",
    "X_SNP = r_objects[\"X_SNP\"].to_numpy()\n",
    "#Cluster_list = r_objects[\"Cluster.list\"]  # list of 1‑based vectors (R style)\n",
    "import pandas as _pd  # local import\n",
    "_df: _pd.DataFrame = r_objects[\"Cluster.df\"]\n",
    "\n",
    "import pandas as _pd  # local import\n",
    "_df: _pd.DataFrame = r_objects[\"Cluster.df\"]\n",
    "# first column = cluster ID, second column = SNP index (1‑based)\n",
    "clust_col, snp_col = _df.columns[:2]\n",
    "_grouped = _df.groupby(clust_col)[snp_col]\n",
    "Cluster_list = [grp.values for _, grp in _grouped]\n",
    "#print(f\"→ Converted Cluster.df with {len(Cluster_list)} clusters.\")\n",
    "\n",
    "# Convert clusters (1‑based R indices) to 0‑based NumPy arrays (1‑based R indices) to 0‑based NumPy arrays\n",
    "Cluster_list_py = [np.asarray(cl, dtype=int) - 1 for cl in Cluster_list]\n",
    "\n",
    "n, p = X_SNP.shape\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X = scaler.fit_transform(X_SNP) / np.sqrt(n)\n",
    "\n",
    "# SNP categories\n",
    "Singletons = np.concatenate([cl for cl in Cluster_list_py if len(cl) == 1]).astype(int)\n",
    "LargerClusters = [cl.astype(int) for cl in Cluster_list_py if len(cl) >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f34eb967-32b8-4278-a012-9c4e59596606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 1000, p = 7297\n",
      "Anzahl Singletons: 3075\n",
      "Anzahl Cluster (>= 2): 1533\n",
      "Anzahl Large-Cluster (>= 5): 134\n"
     ]
    }
   ],
   "source": [
    "# Dimensionen und Anzahl Cluster\n",
    "\n",
    "num_singletons      = sum(1 for cl in Cluster_list_py if len(cl) == 1)\n",
    "num_clusters_ge2    = sum(1 for cl in Cluster_list_py if len(cl) >= 2)\n",
    "num_large_clusters  = sum(1 for cl in Cluster_list_py if len(cl) >= 5)\n",
    "\n",
    "print(f\"n = {n}, p = {p}\")\n",
    "print(f\"Anzahl Singletons: {num_singletons}\")\n",
    "print(f\"Anzahl Cluster (>= 2): {num_clusters_ge2}\")\n",
    "print(f\"Anzahl Large-Cluster (>= 5): {num_large_clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c60e1ee-4621-4801-8234-5db42868ff60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betragskorrelationen |r|:  min = 0.000000,  mean = 0.036704,  max = 0.978502\n",
      "median = 0.028314, Q95 = 0.097908\n"
     ]
    }
   ],
   "source": [
    "# Korrelation Singeltons\n",
    "\n",
    "R = X[:, Singletons].T @ X             \n",
    "# Selbstkorrelationen (Singleton i mit sich selbst) ausschließen\n",
    "R = R.astype(float)\n",
    "R[np.arange(len(Singletons)), Singletons] = np.nan\n",
    "\n",
    "# Signierte Korrelationen\n",
    "min_corr  = np.nanmin(R)\n",
    "mean_corr = np.nanmean(R)\n",
    "max_corr  = np.nanmax(R)\n",
    "\n",
    "# Betragskorrelationen\n",
    "A = np.abs(R)\n",
    "min_abs  = np.nanmin(A)\n",
    "mean_abs = np.nanmean(A)\n",
    "max_abs  = np.nanmax(A)\n",
    "\n",
    "# Robustere Lage-/Tail-Kennzahlen (empfohlen)\n",
    "median_abs = np.nanmedian(A)\n",
    "q95_abs    = np.nanquantile(A, 0.95)\n",
    "\n",
    "print(f\"Betragskorrelationen |r|:  min = {min_abs:.6f},  mean = {mean_abs:.6f},  max = {max_abs:.6f}\")\n",
    "print(f\"median = {median_abs:.6f}, Q95 = {q95_abs:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01619dee-b480-4b38-80d0-80295b68ff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation within the clusters: |r|  median=0.7269, mean=0.7287, Q95=0.9851, max=1.0000, min=0.0633\n"
     ]
    }
   ],
   "source": [
    "# Korrelation Cluster\n",
    "#innerhalb des Clusters\n",
    "\n",
    "vals = []\n",
    "for cl in LargerClusters:\n",
    "    m = len(cl)\n",
    "    if m < 2: \n",
    "        continue\n",
    "    subX = X[:, cl]\n",
    "    R = subX.T @ subX                   # (m, m)\n",
    "    tri = np.triu_indices(m, 1)\n",
    "    vals.append(np.abs(R[tri]))\n",
    "\n",
    "vals = np.concatenate(vals) if vals else np.array([])\n",
    "\n",
    "if vals.size:\n",
    "    print(f\"Correlation within the clusters: |r|  median={np.median(vals):.4f}, mean={vals.mean():.4f}, \"\n",
    "          f\"Q95={np.quantile(vals, 0.95):.4f}, max={vals.max():.4f}, min={vals.min():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d492c34-94f8-46f5-8259-11803ca5c7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leakage |r|: median=0.0324, mean=0.0441, Q95=0.1241, max=0.9756\n"
     ]
    }
   ],
   "source": [
    "# Korrelation Cluster\n",
    "# außerhalb des Clusters\n",
    "\n",
    "all_idx = np.arange(p)\n",
    "leak = np.concatenate([\n",
    "    np.abs((X[:, cl].T @ X[:, np.setdiff1d(all_idx, cl, assume_unique=True)])).ravel()\n",
    "    for cl in LargerClusters if len(cl) > 0\n",
    "]) if LargerClusters else np.array([])\n",
    "\n",
    "\n",
    "print(f\"Leakage |r|: median={np.median(leak):.4f}, mean={leak.mean():.4f}, \"\n",
    "      f\"Q95={np.quantile(leak, 0.95):.4f}, max={leak.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8caaa594-aab8-4503-85c8-33a32c5e2142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anteil lückenloser LargeClusters: 0.037\n",
      "Median coverage: 0.390\n",
      "Gaps (Indexraum): median=2.0, Q95=11.0, max=79.0\n",
      "Anteil gap=1:   0.353\n",
      "Anteil gap<=5:  0.831\n",
      "Anteil gap<=10: 0.945\n"
     ]
    }
   ],
   "source": [
    "# Lage der SNPs der Cluster\n",
    "\n",
    "rows, gaps_all = [], []\n",
    "for cid, cl in enumerate(LargerClusters, start=1):\n",
    "    idx = np.sort(np.asarray(cl, dtype=int))\n",
    "    m = idx.size\n",
    "    gaps = np.diff(idx)                    # Index-Abstände innerhalb des Clusters\n",
    "    gaps_all.append(gaps)\n",
    "    span = int(idx[-1] - idx[0])           # Spannweite im Indexraum\n",
    "    coverage = m / (span + 1) if span >= 0 else np.nan\n",
    "    rows.append(dict(\n",
    "        cluster_id=cid, size=m,\n",
    "        start=int(idx[0]), end=int(idx[-1]),\n",
    "        span=span, coverage=float(coverage),\n",
    "        contiguous=bool(np.all(gaps == 1))\n",
    "    ))\n",
    "\n",
    "pos_idx_df = pd.DataFrame(rows).sort_values([\"size\",\"span\"], ascending=[False, True])\n",
    "\n",
    "# Zusammenfassung\n",
    "gaps_all = np.concatenate(gaps_all) if len(gaps_all) else np.array([])\n",
    "print(f\"Anteil lückenloser LargeClusters: {pos_idx_df['contiguous'].mean():.3f}\")\n",
    "print(f\"Median coverage: {pos_idx_df['coverage'].median():.3f}\")\n",
    "if gaps_all.size:\n",
    "    print(f\"Gaps (Indexraum): median={np.median(gaps_all):.1f}, \"    # Gap = Abstand zum nächsten SNP im selben Cluster\n",
    "          f\"Q95={np.quantile(gaps_all, 0.95):.1f}, max={np.max(gaps_all):.1f}\")\n",
    "\n",
    "\n",
    "# Wie häufig liegen Cluster-Paare „nah beieinander“?\n",
    "\n",
    "near1=near5=near10=0; total=0\n",
    "for cl in LargerClusters:\n",
    "    idx=np.sort(cl); g=np.diff(idx)\n",
    "    total += g.size\n",
    "    near1  += np.sum(g==1)\n",
    "    near5  += np.sum(g<=5)\n",
    "    near10 += np.sum(g<=10)\n",
    "print(f\"Anteil gap=1:   {near1/total:.3f}\")\n",
    "print(f\"Anteil gap<=5:  {near5/total:.3f}\")\n",
    "print(f\"Anteil gap<=10: {near10/total:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5974047f-5d2b-4c88-89a0-e20705ec0acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
