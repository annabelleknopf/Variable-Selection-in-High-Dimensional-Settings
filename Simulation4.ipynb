{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91a066ba-3be2-4198-8fd9-eb9a939c7161",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#\n",
    "#   Fourth set of simulations (Real GWAS data for X)\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "# Logistic regression model logit(pi) = X * beta + epsilon\n",
    "\n",
    "# P(Y = 1) = pi\n",
    "\n",
    "# Sample size n = 1000, \n",
    "\n",
    "# Total number of potential regressors p = 7297\n",
    "\n",
    "\n",
    "# Coefficients beta of model from gamma distribution\n",
    "\n",
    "\n",
    "# Simulation scenarios where causal markers are distributed \n",
    "# differently among clusters of SNPs:\n",
    "\n",
    "\n",
    "# 1)  k = 20 causal SNPs distributed over singletons\n",
    "\n",
    "# 2)  k = 20 causal SNPs distributed over Clusters of at least size 5\n",
    "#            1 SNP per cluster      \n",
    "#\n",
    "\n",
    "# 3)  k = 20 causal SNPs distributed over Clusters of at least size 5\n",
    "#            2 SNPs per cluster      \n",
    "#\n",
    "\n",
    "# 4)  k = 20 causal SNPs distributed over Clusters of at least size 5\n",
    "#            4 SNPs per cluster      \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6193926e-bfda-453b-a1f5-5944a8bdd741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from time import time\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng, Generator\n",
    "from scipy.special import expit as sigmoid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import scale\n",
    "import pyreadr\n",
    "import random\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=r'Environment variable \".*\" redefined by R and overriding existing variable\\.',\n",
    "    category=UserWarning,\n",
    "    module=r\"rpy2\\.rinterface.*\",\n",
    ")\n",
    "\n",
    "from model_selection import (\n",
    "    stepwise_plain,\n",
    "    L0opt_CD,\n",
    "    L0opt_CDPSI,\n",
    "    Select_GSDAR,\n",
    "    lassonet,\n",
    "    lassonet_plus,\n",
    "    deep2stage,\n",
    "    deep2stage_plus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8e8470f-fcac-4f33-870c-c4f618e0fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "CheckCode = False  # switch to False for the full run\n",
    "\n",
    "if CheckCode:\n",
    "    sim_nr = 2\n",
    "    results_folder = \"CheckResults4\"\n",
    "else:\n",
    "    sim_nr = 100\n",
    "    results_folder = \"Results4\"\n",
    "\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "RNG_SEED = 19091303\n",
    "k = 20                      # number of true SNPs in every scenario\n",
    "eff = 15.0                  # effect scaling factor from R code\n",
    "\n",
    "def reseed(seed: int, use_torch: bool = False):\n",
    "    \"\"\"Setzt NumPy/Random (und optional Torch) deterministisch.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if use_torch and (torch is not None):\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def make_call_seed(scenario: int, sim: int, method_idx: int, base: int = 19091303) -> int:\n",
    "    \"\"\"\n",
    "    Stabiler Seed für *einen* Methoden-Call – abgeleitet aus (scenario, sim, method_idx).\n",
    "    So beeinflussen sich Methoden nicht gegenseitig über den RNG-Stream.\n",
    "    \"\"\"\n",
    "    # scenario: 1..4 (dein Mapping)\n",
    "    val = (base ^ (scenario * 97_003) ^ (sim * 1_927_211) ^ (method_idx * 101))\n",
    "    return int(val & 0x7FFF_FFFF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efc02973-5dd7-4619-b18d-96ab96e689e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SNP data\n",
    "r_data_path = os.path.join(\"Data\", \"SNP_data.RData\")\n",
    "if not os.path.exists(r_data_path):\n",
    "    raise FileNotFoundError(f\"{r_data_path} not found – please provide the file.\")\n",
    "\n",
    "r_objects = pyreadr.read_r(r_data_path)\n",
    "X_SNP = r_objects[\"X_SNP\"].to_numpy()\n",
    "#Cluster_list = r_objects[\"Cluster.list\"]  # list of 1‑based vectors (R style)\n",
    "import pandas as _pd  # local import\n",
    "_df: _pd.DataFrame = r_objects[\"Cluster.df\"]\n",
    "# first column = cluster ID, second column = SNP index (1‑based)\n",
    "clust_col, snp_col = _df.columns[:2]\n",
    "_grouped = _df.groupby(clust_col)[snp_col]\n",
    "Cluster_list = [grp.values for _, grp in _grouped]\n",
    "#print(f\"→ Converted Cluster.df with {len(Cluster_list)} clusters.\")\n",
    "\n",
    "# Convert clusters (1‑based R indices) to 0‑based NumPy arrays (1‑based R indices) to 0‑based NumPy arrays\n",
    "Cluster_list_py = [np.asarray(cl, dtype=int) - 1 for cl in Cluster_list]\n",
    "\n",
    "\n",
    "n, p = X_SNP.shape\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X = np.ascontiguousarray(scaler.fit_transform(X_SNP) / np.sqrt(n), dtype=np.float64)\n",
    "\n",
    "# SNP categories\n",
    "Singletons = np.concatenate([cl for cl in Cluster_list_py if len(cl) == 1]).astype(int)\n",
    "LargerClusters = [cl.astype(int) for cl in Cluster_list_py if len(cl) >= 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85e4f59a-20d4-41ea-8574-5738fb6cb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: unified call that adds the correct signature per method\n",
    "def run_method(method, method_name: str, y, X):\n",
    "    \"\"\"Call *method* with the appropriate signature mirroring the R code.\"\"\"\n",
    "    if method_name.startswith(\"stepwise\"):\n",
    "        # stepwise_plain / _reduced / _ff\n",
    "        return method(y, X, model=\"logistic\")\n",
    "    if method_name == \"L0opt_CD\":\n",
    "        return method(y, X, model=\"Logistic\", maxSuppSize=50)\n",
    "    if method_name == \"L0opt_CDPSI\":\n",
    "        return method(y, X, model=\"Logistic\", maxSuppSize=50)\n",
    "    if method_name == \"GSDAR\":\n",
    "        return method(y, X) \n",
    "    if method_name == \"lassonet\":\n",
    "        return method(y, X, model=\"logistic\") \n",
    "    if method_name == \"lassonet_plus\":\n",
    "        return method(y, X, model=\"logistic\") \n",
    "    if method_name == \"deep2stage\":\n",
    "        return method(y, X, model=\"logistic\") \n",
    "    if method_name == \"deep2stage_plus\":\n",
    "        return method(y, X, model=\"logistic\") \n",
    "    # fallback – should not occur\n",
    "    return method(y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "354cd14f-f33e-4aa4-80a5-e5b5330c27ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ETA = 5.0        # erlaubt |logit| ≤ 5  →  p ∈ (0.007, 0.993)\n",
    "def simulate_response(rng: Generator, X_beta: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Generate binary response y ~ Bernoulli(sigmoid(η)) with η bounded.\"\"\"\n",
    "    \n",
    "    # 1. zentrieren\n",
    "    eta = X_beta - X_beta.mean()\n",
    "    \n",
    "    # 2. nur skalieren, wenn der Vektor nicht konstant 0 ist\n",
    "    max_abs = np.max(np.abs(eta))\n",
    "    if max_abs > 0:\n",
    "        eta *= MAX_ETA / max_abs      # |η| ≤ MAX_ETA\n",
    "\n",
    "    # 3. Wahrscheinlichkeiten berechnen\n",
    "    p_vec = sigmoid(eta)\n",
    "    p_vec = np.clip(p_vec, 1e-12, 1 - 1e-12)\n",
    "\n",
    "    # 4. Binäre Antwort generieren\n",
    "    y = rng.binomial(1, p_vec)\n",
    "    # Guarantee both classes (rare edge case)\n",
    "    if y.min() == y.max():\n",
    "        y = rng.binomial(1, 0.5, size=len(y))\n",
    "    return y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc030bb-7510-4d71-a253-dba64322721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: pick causal SNP indices ----------------------------------------\n",
    "\n",
    "def pick_causal_snps(scenario: int, rng: Generator) -> np.ndarray:\n",
    "    if scenario == 1:\n",
    "        return rng.choice(Singletons, k, replace=False)\n",
    "\n",
    "    snps_per_cluster = {2: 1, 3: 2, 4: 4}[scenario]\n",
    "    clusters_needed = k // snps_per_cluster\n",
    "    cluster_idx = rng.choice(len(LargerClusters), clusters_needed, replace=False)\n",
    "    causal = []\n",
    "    for idx in cluster_idx:\n",
    "        causal.extend(rng.choice(LargerClusters[idx], snps_per_cluster, replace=False))\n",
    "    return np.asarray(causal, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ee99dd-2e67-4c1a-a295-d366b4e5215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [stepwise_plain, Select_GSDAR, L0opt_CD, L0opt_CDPSI, lassonet, lassonet_plus, deep2stage, deep2stage_plus]\n",
    "method_names = [\n",
    "    \"stepwise_plain\",\n",
    "    \"GSDAR\",\n",
    "    \"L0opt_CD\",\n",
    "    \"L0opt_CDPSI\",\n",
    "    \"lassonet\",\n",
    "    \"lassonet_plus\",\n",
    "    \"deep2stage\",\n",
    "    \"deep2stage_plus\"\n",
    "]\n",
    "TORCH_METHODS = {\"lassonet\", \"lassonet_plus\", \"deep2stage\", \"deep2stage_plus\"}\n",
    "nr_procedures = len(methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87bce94c-eea6-4383-9675-8424babbb76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results matrices\n",
    "\n",
    "shape = (sim_nr, nr_procedures)\n",
    "mBIC_results = np.zeros(shape)\n",
    "mBIC2_results = np.zeros(shape)\n",
    "mBIC_FP = np.zeros(shape)\n",
    "mBIC2_FP = np.zeros(shape)\n",
    "mBIC_TP = np.zeros(shape)\n",
    "mBIC2_TP = np.zeros(shape)\n",
    "runtime = np.zeros(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ebe627d-0e4d-4524-a330-dc2049b69aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scenario 1: 2 simulation(s)…\n",
      "  sim 1/2\n",
      "  sim 2/2\n",
      "  → saved CheckResults4/Scen1.k_20.pkl\n",
      "\n",
      "Scenario 2: 2 simulation(s)…\n",
      "  sim 1/2\n",
      "  sim 2/2\n",
      "  → saved CheckResults4/Scen2.k_20.pkl\n",
      "\n",
      "Scenario 3: 2 simulation(s)…\n",
      "  sim 1/2\n",
      "  sim 2/2\n",
      "  → saved CheckResults4/Scen3.k_20.pkl\n",
      "\n",
      "Scenario 4: 2 simulation(s)…\n",
      "  sim 1/2\n",
      "  sim 2/2\n",
      "  → saved CheckResults4/Scen4.k_20.pkl\n",
      "\n",
      "All scenarios completed.\n"
     ]
    }
   ],
   "source": [
    "# Main simulation loop \n",
    "\n",
    "rng = default_rng(RNG_SEED)\n",
    "\n",
    "for scenario in (1, 2, 3, 4):  \n",
    "    scen_label = f\"Scen{scenario}\"\n",
    "    print(f\"\\nScenario {scenario}: {sim_nr} simulation(s)…\")\n",
    "\n",
    "    # Reset matrices for this scenario\n",
    "    for arr in (mBIC_results, mBIC2_results, mBIC_FP, mBIC2_FP, mBIC_TP, mBIC2_TP, runtime):\n",
    "        arr.fill(np.nan)\n",
    "\n",
    "    for sim in range(sim_nr):\n",
    "        if sim % 10 == 0 or sim == sim_nr - 1:\n",
    "            print(f\"  sim {sim + 1}/{sim_nr}\")\n",
    "\n",
    "        correct = pick_causal_snps(scenario, rng)\n",
    "        beta_k = rng.choice([-1, 1], k) * rng.gamma(3, 1/3, k)\n",
    "        beta = np.zeros(p)\n",
    "        beta[correct] = eff * beta_k\n",
    "\n",
    "        y = simulate_response(rng, X @ beta)\n",
    "\n",
    "        for i, (method, name) in enumerate(zip(methods, method_names)):\n",
    "            try:\n",
    "                seed_call = make_call_seed(scenario=scenario, sim=sim, method_idx=i)\n",
    "                reseed(seed_call, use_torch=(name in TORCH_METHODS))\n",
    "                \n",
    "                t0 = time()\n",
    "                res = run_method(method, name, y, X)\n",
    "                runtime[sim, i] = time() - t0\n",
    "\n",
    "                m1 = np.asarray(res.model1, dtype=int) - 1\n",
    "                m2 = np.asarray(res.model2, dtype=int) - 1\n",
    "\n",
    "                mBIC_results[sim, i]  = res.mBIC\n",
    "                mBIC2_results[sim, i] = res.mBIC2\n",
    "                mBIC_FP[sim, i]       = np.sum(~np.isin(m1, correct))\n",
    "                mBIC2_FP[sim, i]      = np.sum(~np.isin(m2, correct))\n",
    "                mBIC_TP[sim, i]       = np.sum(np.isin(m1, correct))\n",
    "                mBIC2_TP[sim, i]      = np.sum(np.isin(m2, correct))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    ⚠️ {name} failed: {e}\")\n",
    "\n",
    "    out_file = os.path.join(results_folder, f\"{scen_label}.k_{k}.pkl\")\n",
    "    with open(out_file, \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            \"mBIC.results\": mBIC_results.copy(),\n",
    "            \"mBIC2.results\": mBIC2_results.copy(),\n",
    "            \"mBIC.FP\": mBIC_FP.copy(),\n",
    "            \"mBIC2.FP\": mBIC2_FP.copy(),\n",
    "            \"mBIC.TP\": mBIC_TP.copy(),\n",
    "            \"mBIC2.TP\": mBIC2_TP.copy(),\n",
    "            \"runtime\": runtime.copy(),\n",
    "            \"method_names\": method_names,\n",
    "            \"k\": k,\n",
    "            \"scenario\": scenario,\n",
    "            \"n\": n,\n",
    "            \"p\": p,\n",
    "        }, f)\n",
    "    print(f\"  → saved {out_file}\")\n",
    "\n",
    "print(\"\\nAll scenarios completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f039c9ef-bbba-4234-97dc-0e348365f394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effefdb6-acf7-467f-a381-ba3048e116bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b06b714-e93d-43f1-8dd2-e9639864b066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
