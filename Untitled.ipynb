{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a2c32-19c5-42cc-8f0d-5c40f4feb9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, pickle, random, numpy as np\n",
    "from numpy.random import default_rng\n",
    "from scipy.linalg import toeplitz\n",
    "from sklearn.preprocessing import scale\n",
    "from time import time\n",
    "import torch\n",
    "\n",
    "from model_selection import lassonet  # ggf. zusätzlich: lassonet_plus\n",
    "\n",
    "# --------- Pfade / Muster ----------\n",
    "input_dir  = \"Results1\"\n",
    "output_dir = \"Results1_neu\"\n",
    "file_pattern = \"Sim1.k_*.rho_*.pkl\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --------- Daten-Parameter (bei Bedarf anpassen) ----------\n",
    "n = 500\n",
    "p = 1000\n",
    "p_vec = np.arange(p)\n",
    "\n",
    "# --------- Repro-Helper (wie im Original) ----------\n",
    "def make_rng(k, rho, sim, base=19091303):\n",
    "    return default_rng(base + 100000*k + int(round(10000*rho)) + sim)\n",
    "\n",
    "def reseed(seed: int, use_torch: bool = False):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if use_torch and (torch is not None):\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def make_call_seed(k: int, rho: float, sim: int, method_idx: int) -> int:\n",
    "    rho10 = int(round(10 * rho))\n",
    "    base = 1_000_000 * k + 10_000 * rho10 + sim\n",
    "    return int((base * 1_004_659 + method_idx * 97) % 2_147_483_647)\n",
    "\n",
    "def ar1_cor(p, rho):\n",
    "    return toeplitz(rho ** np.arange(p))\n",
    "\n",
    "# Welche Methoden-Spalten sollen ersetzt werden?\n",
    "TARGETS = {\n",
    "    \"lassonet\": (lassonet, True),\n",
    "    # \"lassonet_plus\": (lassonet_plus, True),\n",
    "}\n",
    "\n",
    "def process_file(in_path: str):\n",
    "    with open(in_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    method_names = data[\"method_names\"]\n",
    "    sim_nr, nr_procedures = data[\"mBIC_results\"].shape\n",
    "    k   = data[\"k\"]\n",
    "    rho = data[\"rho\"]\n",
    "\n",
    "    # zu ersetzende Spalten finden\n",
    "    target_cols = {}\n",
    "    for name in TARGETS.keys():\n",
    "        if name in method_names:\n",
    "            target_cols[name] = method_names.index(name)\n",
    "\n",
    "    # Falls keine Zielmethode in der Datei ist: unverändert kopieren\n",
    "    out_path = os.path.join(output_dir, os.path.basename(in_path))\n",
    "    if not target_cols:\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(f\"[copy] {os.path.basename(in_path)} → {out_path} (keine Zielmethode gefunden)\")\n",
    "        return\n",
    "\n",
    "    print(f\"Update: {os.path.basename(in_path)} | k={k}, rho={rho} | sims={sim_nr}\")\n",
    "    Sigma = ar1_cor(p, rho)\n",
    "\n",
    "    for sim in range(sim_nr):\n",
    "        if sim % 10 == 0:\n",
    "            print(f\"  Simulation {sim+1}/{sim_nr}\")\n",
    "\n",
    "        # Daten wie im ursprünglichen Lauf rekonstruieren\n",
    "        rng = make_rng(k, rho, sim)\n",
    "        correct_model = rng.choice(p_vec, k, replace=False)\n",
    "        beta = np.zeros(p)\n",
    "        beta[correct_model] = rng.normal(0, 1, size=k)\n",
    "\n",
    "        x = rng.multivariate_normal(mean=np.zeros(p), cov=Sigma, size=n)\n",
    "        y = x @ beta + rng.normal(0, 1, size=n)\n",
    "\n",
    "        X = np.ascontiguousarray(scale(x) / np.sqrt(n), dtype=np.float64)\n",
    "        y_std = np.ascontiguousarray(scale(y), dtype=np.float64)\n",
    "\n",
    "        # Zielmethoden neu rechnen\n",
    "        for name, col_idx in target_cols.items():\n",
    "            method, uses_torch = TARGETS[name]\n",
    "            try:\n",
    "                seed_call = make_call_seed(k, rho, sim, col_idx)\n",
    "                reseed(seed_call, use_torch=uses_torch)\n",
    "\n",
    "                t0 = time()\n",
    "                result = method(y_std, X)\n",
    "                t1 = time()\n",
    "\n",
    "                model1 = result.model1 - 1\n",
    "                model2 = result.model2 - 1\n",
    "\n",
    "                data[\"mBIC_results\"][sim, col_idx]  = result.mBIC\n",
    "                data[\"mBIC2_results\"][sim, col_idx] = result.mBIC2\n",
    "                data[\"mBIC_FP\"][sim, col_idx]       = np.sum(~np.isin(model1, correct_model))\n",
    "                data[\"mBIC2_FP\"][sim, col_idx]      = np.sum(~np.isin(model2, correct_model))\n",
    "                data[\"mBIC_TP\"][sim, col_idx]       = np.sum(np.isin(model1, correct_model))\n",
    "                data[\"mBIC2_TP\"][sim, col_idx]      = np.sum(np.isin(model2, correct_model))\n",
    "                data[\"runtime\"][sim, col_idx]       = t1 - t0\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    Fehler '{name}' in Sim {sim+1}: {e} (alte Werte bleiben erhalten)\")\n",
    "\n",
    "    # in neuen Ordner schreiben\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"  → gespeichert in: {out_path}\")\n",
    "\n",
    "# --- Lauf über alle Dateien im Eingabeordner ---\n",
    "files = sorted(glob.glob(os.path.join(input_dir, file_pattern)))\n",
    "if not files:\n",
    "    print(\"Keine passenden Eingabedateien gefunden.\")\n",
    "else:\n",
    "    for fp in files:\n",
    "        process_file(fp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
