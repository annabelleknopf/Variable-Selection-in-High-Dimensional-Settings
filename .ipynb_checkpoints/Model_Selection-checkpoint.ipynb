{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba607f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/rpy2/rinterface/__init__.py:1211: UserWarning: Environment variable \"BASH_FUNC_create_passwd%%\" redefined by R and overriding existing variable. Current: \"() {  tr -cd 'a-zA-Z0-9' < /dev/urandom 2> /dev/null | head -c${1:-8}\n",
      "}\", R: \"() {  tr -cd 'a-zA-Z0-9' < /dev/urandom 2> /dev/null | head -c${1:-8}}\"\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/rpy2/rinterface/__init__.py:1211: UserWarning: Environment variable \"BASH_FUNC_find_port%%\" redefined by R and overriding existing variable. Current: \"() {  local host=\"${1:-localhost}\";\n",
      " local min_port=${2:-8888};\n",
      " local max_port=${3:-8988};\n",
      " local port_range=($(shuf -i ${min_port}-${max_port}));\n",
      " local retries=1;\n",
      " for ((attempt=0; attempt<=$retries; attempt++))\n",
      " do\n",
      " for port in \"${port_range[@]}\";\n",
      " do\n",
      " if port_used \"${host}:${port}\"; then\n",
      " continue;\n",
      " fi;\n",
      " echo \"${port}\";\n",
      " return 0;\n",
      " done;\n",
      " done;\n",
      " echo \"error: failed to find available port in range ${min_port}..${max_port}\" 1>&2;\n",
      " return 1\n",
      "}\", R: \"() {  local host=\"${1:-localhost}\"; local min_port=${2:-8888}; local max_port=${3:-8988}; local port_range=($(shuf -i ${min_port}-${max_port})); local retries=1; for ((attempt=0; attempt<=$retries; attempt++)) do for port in \"${port_range[@]}\"; do if port_used \"${host}:${port}\"; then continue; fi; echo \"${port}\"; return 0; done; done; echo \"error: failed to find available port in range ${min_port}..${max_port}\" 1>&2; return 1}\"\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/rpy2/rinterface/__init__.py:1211: UserWarning: Environment variable \"BASH_FUNC_port_used%%\" redefined by R and overriding existing variable. Current: \"() {  local port=\"${1#*:}\";\n",
      " local host=$((expr \"${1}\" : '\\(.*\\):' || echo \"localhost\") | awk 'END{print $NF}');\n",
      " local port_strategies=(port_used_nc port_used_lsof port_used_bash port_used_python port_used_python3);\n",
      " for strategy in ${port_strategies[@]};\n",
      " do\n",
      " $strategy $host $port;\n",
      " status=$?;\n",
      " if [[ \"$status\" == \"0\" ]] || [[ \"$status\" == \"1\" ]]; then\n",
      " return $status;\n",
      " fi;\n",
      " done;\n",
      " return 127\n",
      "}\", R: \"() {  local port=\"${1#*:}\"; local host=$((expr \"${1}\" : '\\(.*\\):' || echo \"localhost\") | awk 'END{print $NF}'); local port_strategies=(port_used_nc port_used_lsof port_used_bash port_used_python port_used_python3); for strategy in ${port_strategies[@]}; do $strategy $host $port; status=$?; if [[ \"$status\" == \"0\" ]] || [[ \"$status\" == \"1\" ]]; then return $status; fi; done; return 127}\"\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/rpy2/rinterface/__init__.py:1211: UserWarning: Environment variable \"BASH_FUNC_random_number%%\" redefined by R and overriding existing variable. Current: \"() {  shuf -i ${1}-${2} -n 1\n",
      "}\", R: \"() {  shuf -i ${1}-${2} -n 1}\"\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/rpy2/rinterface/__init__.py:1211: UserWarning: Environment variable \"BASH_FUNC_source_helpers%%\" redefined by R and overriding existing variable. Current: \"() {  function random_number () \n",
      " { \n",
      " shuf -i ${1}-${2} -n 1\n",
      " };\n",
      " export -f random_number;\n",
      " function port_used_python () \n",
      " { \n",
      " python -c \"import socket; socket.socket().connect(('$1',$2))\" > /dev/null 2>&1\n",
      " };\n",
      " function port_used_python3 () \n",
      " { \n",
      " python3 -c \"import socket; socket.socket().connect(('$1',$2))\" > /dev/null 2>&1\n",
      " };\n",
      " function port_used_nc () \n",
      " { \n",
      " nc -w 2 \"$1\" \"$2\" < /dev/null > /dev/null 2>&1\n",
      " };\n",
      " function port_used_lsof () \n",
      " { \n",
      " lsof -i :\"$2\" > /dev/null 2>&1\n",
      " };\n",
      " function port_used_bash () \n",
      " { \n",
      " local bash_supported=$(strings /bin/bash 2> /dev/null | grep tcp);\n",
      " if [ \"$bash_supported\" == \"/dev/tcp/*/*\" ]; then\n",
      " ( : < /dev/tcp/$1/$2 ) > /dev/null 2>&1;\n",
      " else\n",
      " return 127;\n",
      " fi\n",
      " };\n",
      " function port_used () \n",
      " { \n",
      " local port=\"${1#*:}\";\n",
      " local host=$((expr \"${1}\" : '\\(.*\\):' || echo \"localhost\") | awk 'END{print $NF}');\n",
      " local port_strategies=(port_used_nc port_used_lsof port_used_bash port_used_python port_used_python3);\n",
      " for strategy in ${port_strategies[@]};\n",
      " do\n",
      " $strategy $host $port;\n",
      " status=$?;\n",
      " if [[ \"$status\" == \"0\" ]] || [[ \"$status\" == \"1\" ]]; then\n",
      " return $status;\n",
      " fi;\n",
      " done;\n",
      " return 127\n",
      " };\n",
      " export -f port_used;\n",
      " function find_port () \n",
      " { \n",
      " local host=\"${1:-localhost}\";\n",
      " local min_port=${2:-8888};\n",
      " local max_port=${3:-8988};\n",
      " local port_range=($(shuf -i ${min_port}-${max_port}));\n",
      " local retries=1;\n",
      " for ((attempt=0; attempt<=$retries; attempt++))\n",
      " do\n",
      " for port in \"${port_range[@]}\";\n",
      " do\n",
      " if port_used \"${host}:${port}\"; then\n",
      " continue;\n",
      " fi;\n",
      " echo \"${port}\";\n",
      " return 0;\n",
      " done;\n",
      " done;\n",
      " echo \"error: failed to find available port in range ${min_port}..${max_port}\" 1>&2;\n",
      " return 1\n",
      " };\n",
      " export -f find_port;\n",
      " function wait_until_port_used () \n",
      " { \n",
      " local port=\"${1}\";\n",
      " local time=\"${2:-30}\";\n",
      " for ((i=1; i<=time*2; i++))\n",
      " do\n",
      " port_used \"${port}\";\n",
      " port_status=$?;\n",
      " if [ \"$port_status\" == \"0\" ]; then\n",
      " return 0;\n",
      " else\n",
      " if [ \"$port_status\" == \"127\" ]; then\n",
      " echo \"commands to find port were either not found or inaccessible.\";\n",
      " echo \"command options are lsof, nc, bash's /dev/tcp, or python (or python3) with socket lib.\";\n",
      " return 127;\n",
      " fi;\n",
      " fi;\n",
      " sleep 0.5;\n",
      " done;\n",
      " return 1\n",
      " };\n",
      " export -f wait_until_port_used;\n",
      " function create_passwd () \n",
      " { \n",
      " tr -cd 'a-zA-Z0-9' < /dev/urandom 2> /dev/null | head -c${1:-8}\n",
      " };\n",
      " export -f create_passwd\n",
      "}\", R: \"() {  function random_number ()  {  shuf -i ${1}-${2} -n 1 }; export -f random_number; function port_used_python ()  {  python -c \"import socket; socket.socket().connect(('$1',$2))\" > /dev/null 2>&1 }; function port_used_python3 ()  {  python3 -c \"import socket; socket.socket().connect(('$1',$2))\" > /dev/null 2>&1 }; function port_used_nc ()  {  nc -w 2 \"$1\" \"$2\" < /dev/null > /dev/null 2>&1 }; function port_used_lsof ()  {  lsof -i :\"$2\" > /dev/null 2>&1 }; function port_used_bash ()  {  local bash_supported=$(strings /bin/bash 2> /dev/null | grep tcp); if [ \"$bash_supported\" == \"/dev/tcp/*/*\" ]; then ( : < /dev/tcp/$1/$2 ) > /dev/null 2>&1; else return 127; fi }; function port_used ()  {  local port=\"${1#*:}\"; local host=$((expr \"${1}\" : '\\(.*\\):' || echo \"localhost\") | awk 'END{print $NF}'); local port_strategies=(port_used_nc port_used_lsof port_used_bash port_used_python port_used_python3); for strategy in ${port_strategies[@]}; do $strategy $host $port; status=$?; if [[ \"$status\" == \"0\" ]] || [[ \"$status\" == \"1\" ]]; then return $status; fi; done; return 127 }; export -f port_used; function find_port ()  {  local host=\"${1:-localhost}\"; local min_port=${2:-8888}; local max_port=${3:-8988}; local port_range=($(shuf -i ${min_port}-${max_port})); local retries=1; for ((attempt=0; attempt<=$retries; attempt++)) do for port in \"${port_range[@]}\"; do if port_used \"${host}:${port}\"; then continue; fi; echo \"${port}\"; return 0; done; done; echo \"error: failed to find available port in range ${min_port}..${max_port}\" 1>&2; return 1 }; export -f find_port; function wait_until_port_used ()  {  local port=\"${1}\"; local time=\"${2:-30}\"; for ((i=1; i<=time*2; i++)) do port_used \"${port}\"; port_status=$?; if [ \"$port_status\" == \"0\" ]; then return 0; else if [ \"$port_status\" == \"127\" ]; then echo \"commands to find port were either not found or inaccessible.\"; echo \"command options are lsof, nc, bash's /dev/tcp, or python (or python3) with socket lib.\"; return 127; fi; fi; sleep 0.5; done; return 1 }; export -f wait_until_port_used; function create_passwd ()  {  tr -cd 'a-zA-Z0-9' < /dev/urandom 2> /dev/null | head -c${1:-8} }; export -f create_passwd}\"\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/rpy2/rinterface/__init__.py:1211: UserWarning: Environment variable \"BASH_FUNC_wait_until_port_used%%\" redefined by R and overriding existing variable. Current: \"() {  local port=\"${1}\";\n",
      " local time=\"${2:-30}\";\n",
      " for ((i=1; i<=time*2; i++))\n",
      " do\n",
      " port_used \"${port}\";\n",
      " port_status=$?;\n",
      " if [ \"$port_status\" == \"0\" ]; then\n",
      " return 0;\n",
      " else\n",
      " if [ \"$port_status\" == \"127\" ]; then\n",
      " echo \"commands to find port were either not found or inaccessible.\";\n",
      " echo \"command options are lsof, nc, bash's /dev/tcp, or python (or python3) with socket lib.\";\n",
      " return 127;\n",
      " fi;\n",
      " fi;\n",
      " sleep 0.5;\n",
      " done;\n",
      " return 1\n",
      "}\", R: \"() {  local port=\"${1}\"; local time=\"${2:-30}\"; for ((i=1; i<=time*2; i++)) do port_used \"${port}\"; port_status=$?; if [ \"$port_status\" == \"0\" ]; then return 0; else if [ \"$port_status\" == \"127\" ]; then echo \"commands to find port were either not found or inaccessible.\"; echo \"command options are lsof, nc, bash's /dev/tcp, or python (or python3) with socket lib.\"; return 127; fi; fi; sleep 0.5; done; return 1}\"\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/rpy2/rinterface/__init__.py:1211: UserWarning: Environment variable \"PWD\" redefined by R and overriding existing variable. Current: \"/\", R: \"/dss/dsshome1/0C/ra96quq2/MA\"\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/rpy2/rinterface/__init__.py:1211: UserWarning: Environment variable \"LD_LIBRARY_PATH\" redefined by R and overriding existing variable. Current: \"/usr/lib/R/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/default-java/lib/server\", R: \"/usr/lib/R/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/default-java/lib/server:/usr/lib/R/lib:/usr/lib/x86_64-linux-gnu:/usr/lib/jvm/default-java/lib/server\"\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/rpy2/rinterface/__init__.py:1211: UserWarning: Environment variable \"R_LIBS_SITE\" redefined by R and overriding existing variable. Current: \"/usr/local/lib/R/site-library/:/usr/local/lib/R/site-library:/usr/lib/R/site-library:/usr/lib/R/library\", R: \"/usr/local/lib/R/site-library/:/usr/local/lib/R/site-library/:/usr/local/lib/R/site-library/:/usr/local/lib/R/site-library:/usr/lib/R/site-library:/usr/lib/R/library:/usr/lib/R/library:/usr/lib/R/library\"\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/rpy2/rinterface/__init__.py:1211: UserWarning: Environment variable \"R_PAPERSIZE_USER\" redefined by R and overriding existing variable. Current: \"a4\", R: \"letter\"\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/rpy2/rinterface/__init__.py:1211: UserWarning: Environment variable \"R_SESSION_TMPDIR\" redefined by R and overriding existing variable. Current: \"/tmp/Rtmpf1P6HP\", R: \"/tmp/RtmpRXAzFr\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import itertools as it\n",
    "from dataclasses import dataclass\n",
    "from functools import wraps\n",
    "import numpy as np\n",
    "import pandas as pd          \n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri, numpy2ri\n",
    "import os\n",
    "from rpy2.robjects.vectors import FloatVector\n",
    "from lassonet import LassoNetRegressor, LassoNetClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from numpy import log as ln\n",
    "import itertools as it\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=r'Environment variable \".*\" redefined by R and overriding existing variable\\.',\n",
    "    category=UserWarning,\n",
    "    module=r\"rpy2\\.rinterface.*\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7217ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined converter (no global activate/deactivate)\n",
    "_CONV = ro.default_converter + pandas2ri.converter + numpy2ri.converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a51349",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>ListVector with 2 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            value\n",
       "            </th>\n",
       "            <td>\n",
       "            <rpy2.rinterface.SexpClosure object at 0x7f2ebae24f50> [3]\n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "          <tr>\n",
       "            <th>\n",
       "            visible\n",
       "            </th>\n",
       "            <td>\n",
       "            <rpy2.rinterface.BoolSexpVector object at 0x7f2ebaf6efd0> [10]\n",
       "            </td>\n",
       "          </tr>\n",
       "        \n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.ListVector object at 0x7f2fcc27f610> [19]\n",
       "R classes: ('list',)\n",
       "[SexpClosure, BoolSexpVector]\n",
       "  value: <class 'rpy2.rinterface.SexpClosure'>\n",
       "  <rpy2.rinterface.SexpClosure object at 0x7f2ebaf2d110> [3]\n",
       "  visible: <class 'rpy2.rinterface.BoolSexpVector'>\n",
       "  <rpy2.rinterface.BoolSexpVector object at 0x7f2ebaedd810> [10]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source Init.R that holds the R functions\n",
    "script = Path(\"Init.R\").resolve()\n",
    "ro.r['source'](script.as_posix())\n",
    "\n",
    "# in .py Datei\n",
    "# script = Path(__file__).with_name(\"Init.R\").resolve()\n",
    "# ro.r['source'](file=script.as_posix(), chdir=True, encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c1d9276",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# R-Funktionen in Python-Handles überführen\n",
    "stepwise_plain_r   = ro.globalenv[\"stepwise_plain\"]\n",
    "stepwise_reduced_r = ro.globalenv[\"stepwise_reduced\"]\n",
    "stepwise_ff_r      = ro.globalenv[\"stepwise_ff\"]\n",
    "L0opt_CD_r         = ro.globalenv[\"L0opt_CD\"]\n",
    "L0opt_CDPSI_r      = ro.globalenv[\"L0opt_CDPSI\"]\n",
    "Select_GSDAR_r     = ro.globalenv[\"Select_GSDAR\"]\n",
    "mbic_r  = ro.globalenv[\"mbic_py\"]\n",
    "mbic2_r = ro.globalenv[\"mbic2_py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bf83635",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Structure of the results \n",
    "@dataclass\n",
    "class ModelSelResult:\n",
    "    mBIC:   float\n",
    "    mBIC2:  float\n",
    "    model1: np.ndarray   # Indizes (1-basiert, wie in R) des mBIC-Optimums\n",
    "    model2: np.ndarray   # Indizes des mBIC2-Optimums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e0e6e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def _to_r_numeric_vector(arr):\n",
    "    \"\"\"Return an R 'numeric' vector without dimensions.\"\"\"\n",
    "    return FloatVector(np.asarray(arr, dtype=float).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bb7400f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Dekorator, der den lokalen Converter ein- und ausschaltet\n",
    "def _with_conversion(func):\n",
    "    @wraps(func)\n",
    "    def _wrapper(*args, **kwargs):\n",
    "        with _CONV.context():\n",
    "            return func(*args, **kwargs)\n",
    "    return _wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b10f83-8b85-4fdc-98c7-acdd1a361adb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@_with_conversion\n",
    "def _mbic_bigstep(loglik: float, n: int, k: int, p: int, const: float = 4.0) -> float:\n",
    "    return float(np.asarray(mbic_r(loglik, n, k, p, const=const))[0])\n",
    "\n",
    "@_with_conversion\n",
    "def _mbic2_bigstep(loglik: float, n: int, k: int, p: int, const: float = 4.0) -> float:\n",
    "    return float(np.asarray(mbic2_r(loglik, n, k, p, const=const))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cf1c416-6677-4a81-8bd5-ddd123ea9d22",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Stabilität des Trainings\n",
    "def _prepare_for_lassonet(X, y):\n",
    "   \n",
    "    # 1) near-zero-Var-Spalten entschärfen (verhindert Grad/Weight-Explosionen)\n",
    "    s = X.std(axis=0, ddof=0)\n",
    "    near_zero = s < 1e-12\n",
    "    if near_zero.any():\n",
    "        X = X.copy()\n",
    "        X[:, near_zero] = 0.0  # konstant setzen\n",
    "\n",
    "    X = X.astype(np.float32, copy=False)\n",
    "    y = y.astype(np.float32, copy=False)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e29bfefb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Python-freundliche Wrapper\n",
    "@_with_conversion\n",
    "def stepwise_plain(y: np.ndarray,\n",
    "                   X: np.ndarray,\n",
    "                   model: str = \"linear\") -> ModelSelResult:\n",
    "    y_r = _to_r_numeric_vector(y)\n",
    "    res = stepwise_plain_r(y_r, X, model)\n",
    "    return ModelSelResult(\n",
    "        mBIC=float(res[0]),\n",
    "        mBIC2=float(res[1]),\n",
    "        model1=np.asarray(res[2], dtype=int),\n",
    "        model2=np.asarray(res[3], dtype=int),\n",
    "    )\n",
    "\n",
    "@_with_conversion\n",
    "def stepwise_reduced(y: np.ndarray,\n",
    "                     X: np.ndarray,\n",
    "                     model: str = \"linear\") -> ModelSelResult:\n",
    "    y_r = _to_r_numeric_vector(y)\n",
    "    res = stepwise_reduced_r(y_r, X, model)\n",
    "    return ModelSelResult(\n",
    "        mBIC=float(res[0]),\n",
    "        mBIC2=float(res[1]),\n",
    "        model1=np.asarray(res[2], dtype=int),\n",
    "        model2=np.asarray(res[3], dtype=int),\n",
    "    )\n",
    "\n",
    "@_with_conversion\n",
    "def stepwise_ff(y: np.ndarray,\n",
    "                X: np.ndarray,\n",
    "                model: str = \"linear\") -> ModelSelResult:\n",
    "    y_r = _to_r_numeric_vector(y)\n",
    "    res = stepwise_ff_r(y_r, X, model)\n",
    "    return ModelSelResult(\n",
    "        mBIC=float(res[0]),\n",
    "        mBIC2=float(res[1]),\n",
    "        model1=np.asarray(res[2], dtype=int),\n",
    "        model2=np.asarray(res[3], dtype=int),\n",
    "    )\n",
    "\n",
    "@_with_conversion\n",
    "def L0opt_CD(\n",
    "        y: np.ndarray,\n",
    "        X: np.ndarray,\n",
    "        model: str = \"SquaredError\",\n",
    "        maxSuppSize: int | None = None,\n",
    ") -> ModelSelResult:\n",
    "    y_r = _to_r_numeric_vector(y)\n",
    "\n",
    "    if maxSuppSize is None:\n",
    "        # Ohne Argument aufrufen – R nimmt dann maxSuppSize = NA\n",
    "        res = L0opt_CD_r(y_r, X, model)\n",
    "    else:\n",
    "        # Wert explizit übergeben\n",
    "        res = L0opt_CD_r(y_r, X, model, maxSuppSize=maxSuppSize)\n",
    "\n",
    "    return ModelSelResult(\n",
    "        mBIC=float(res[0]),\n",
    "        mBIC2=float(res[1]),\n",
    "        model1=np.asarray(res[2], dtype=int),\n",
    "        model2=np.asarray(res[3], dtype=int),\n",
    "    )\n",
    "\n",
    "@_with_conversion\n",
    "def L0opt_CDPSI(\n",
    "        y: np.ndarray,\n",
    "        X: np.ndarray,\n",
    "        model: str = \"SquaredError\",\n",
    "        maxSuppSize: int | None = None,\n",
    ") -> ModelSelResult:\n",
    "    y_r = _to_r_numeric_vector(y)\n",
    "\n",
    "    if maxSuppSize is None:\n",
    "        res = L0opt_CDPSI_r(y_r, X, model)\n",
    "    else:\n",
    "        res = L0opt_CDPSI_r(y_r, X, model, maxSuppSize=maxSuppSize)\n",
    "\n",
    "    return ModelSelResult(\n",
    "        mBIC=float(res[0]),\n",
    "        mBIC2=float(res[1]),\n",
    "        model1=np.asarray(res[2], dtype=int),\n",
    "        model2=np.asarray(res[3], dtype=int),\n",
    "    )\n",
    "\n",
    "@_with_conversion\n",
    "def Select_GSDAR(y: np.ndarray,\n",
    "                 X: np.ndarray) -> ModelSelResult:\n",
    "    y_r = _to_r_numeric_vector(y)\n",
    "    res = Select_GSDAR_r(y_r, X)\n",
    "    return ModelSelResult(\n",
    "        mBIC=float(res[0]),\n",
    "        mBIC2=float(res[1]),\n",
    "        model1=np.asarray(res[2], dtype=int),\n",
    "        model2=np.asarray(res[3], dtype=int),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49e4b637-4c2e-48e1-b071-505a8de9587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lassonet(\n",
    "    y: np.ndarray,\n",
    "    X: np.ndarray,\n",
    "    model: str = \"linear\",\n",
    "    *,\n",
    "    M: int | None = None,\n",
    "    path_multiplier: float | None = None,\n",
    "    hidden_dims: tuple[int, ...] | None = None,\n",
    "    n_iters: int | None = None,\n",
    "    early_patience: int | None = None,\n",
    "    no_improve_patience: int | None = None,\n",
    "    random_state: int | None = None,\n",
    "    device: str | None = None,\n",
    ") -> ModelSelResult:\n",
    "    \"\"\"\n",
    "    LassoNet-Pfad auswerten und bestes Modell (mBIC/mBIC2) wählen.\n",
    "    Verbesserungssignal = (mBIC besser) ODER (k = |Support| sinkt).\n",
    "    Abbruch nach 'no_improve_patience' aufeinanderfolgenden Supports ohne Verbesserungssignal.\n",
    "    \"\"\"\n",
    "    # ---- Defaults (wie bisher) ----\n",
    "    NO_IMPROVE_PATIENCE = 4 if no_improve_patience is None else no_improve_patience\n",
    "    TOL = 1e-9\n",
    "    SAT_DELTA = 5\n",
    "    HIDDEN_DIMS = (4,) if hidden_dims is None else hidden_dims\n",
    "    PATH_MULTIPLIER = 1.08 if path_multiplier is None else path_multiplier\n",
    "    N_ITERS = 100 if n_iters is None else n_iters\n",
    "    EARLY_PATIENCE = 2 if early_patience is None else early_patience\n",
    "    RANDOM_STATE = 42 if random_state is None else random_state\n",
    "    M = 30 if M is None else M\n",
    "    DEVICE = \"cpu\" if device is None else device\n",
    "    BATCH_SIZE = min(X.shape[0], 512)\n",
    "\n",
    "    # ---- Vorbereitungen ----\n",
    "    model = model.lower().strip()\n",
    "    if model not in (\"linear\", \"logistic\"):\n",
    "        raise ValueError(\"lassonet: model must be 'linear' or 'logistic'.\")\n",
    "    is_logistic = (model == \"logistic\")\n",
    "\n",
    "    n, p = X.shape\n",
    "    SAT_CUTOFF = min(int(p/2),int(n/2),100)\n",
    "    K_MAX = SAT_CUTOFF\n",
    "\n",
    "    def _ll_full(supp: np.ndarray) -> tuple[float, int]:\n",
    "        \"\"\"Log-Likelihood für gegebenen Support.\"\"\"\n",
    "        k = supp.size\n",
    "        if k == 0:\n",
    "            if is_logistic:\n",
    "                p_hat = float(y.mean())\n",
    "                p_hat = min(max(p_hat, 1e-12), 1 - 1e-12)\n",
    "                ll = float((y * np.log(p_hat) + (1 - y) * np.log(1 - p_hat)).sum())\n",
    "            else:\n",
    "                sigma2_0 = max(float(np.var(y, ddof=0)), 1e-12)\n",
    "                ll = -0.5 * n * np.log(sigma2_0)\n",
    "            return ll, 0\n",
    "\n",
    "        Xk = X[:, supp]\n",
    "        if is_logistic:\n",
    "            mdl = LogisticRegression(penalty=None, solver=\"lbfgs\", max_iter=2000).fit(Xk, y.astype(int))\n",
    "            proba = np.clip(mdl.predict_proba(Xk)[:, 1], 1e-12, 1 - 1e-12)\n",
    "            ll = float((y * np.log(proba) + (1 - y) * np.log(1 - proba)).sum())\n",
    "        else:\n",
    "            mdl = LinearRegression().fit(Xk, y)\n",
    "            rss = float(((mdl.predict(Xk) - y) ** 2).sum())\n",
    "            sigma2 = max(rss / n, 1e-12)\n",
    "            ll = -0.5 * n * np.log(sigma2)\n",
    "        return ll, k\n",
    "\n",
    "    net_cls = LassoNetClassifier if is_logistic else LassoNetRegressor\n",
    "    net = net_cls(\n",
    "        hidden_dims=HIDDEN_DIMS,\n",
    "        path_multiplier=PATH_MULTIPLIER,\n",
    "        lambda_start=\"auto\",\n",
    "        n_iters=N_ITERS,\n",
    "        patience=EARLY_PATIENCE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        val_size=0.0,\n",
    "        random_state=RANDOM_STATE,\n",
    "        M=M,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    # Vorher: X war bereits scale(x)/sqrt(n); wir hatten wieder *sqrt(n) gemacht.\n",
    "    # Für Stabilität beim Netz: bewusst *nicht* zurückskalieren.\n",
    "    #X_net, y_net = _prepare_for_lassonet(X, y)\n",
    "    #X_path = X_net\n",
    "    #y_fit  = y_net\n",
    "\n",
    "    X_path = X * float(np.sqrt(n))\n",
    "    y_fit = y.astype(int) if is_logistic else y\n",
    "\n",
    "    best_mbic = float(\"inf\");   best_sup_mbic = np.array([], dtype=int);   patience_mbic = 0\n",
    "    best_mbic2 = float(\"inf\");  best_sup_mbic2 = np.array([], dtype=int);  patience_mbic2 = 0\n",
    "    best_k_for_mbic  = np.inf\n",
    "    best_k_for_mbic2 = np.inf\n",
    "\n",
    "    seen_supports: set[tuple[int, ...]] = set()\n",
    "\n",
    "    for _, ckpt in enumerate(net.path(X_path, y_fit)):\n",
    "        selected = getattr(ckpt, \"selected\", getattr(ckpt, \"selected_features_\", None))\n",
    "        if selected is None:\n",
    "            continue\n",
    "\n",
    "        mask = np.asarray(selected, dtype=bool)\n",
    "        df = int(mask.sum())\n",
    "        if df >= SAT_CUTOFF:\n",
    "            continue\n",
    "\n",
    "        supp = np.flatnonzero(mask)\n",
    "        key = tuple(supp.tolist())\n",
    "        if key in seen_supports:\n",
    "            continue\n",
    "        seen_supports.add(key)\n",
    "\n",
    "        ll, k = _ll_full(supp)\n",
    "        mbic  = _mbic_bigstep(ll, n, k, p)\n",
    "        mbic2 = _mbic2_bigstep(ll, n, k, p)\n",
    "\n",
    "        # mBIC\n",
    "        improved_val = (mbic < best_mbic - TOL)\n",
    "        improved_k   = (k < best_k_for_mbic)\n",
    "        if improved_val or improved_k:\n",
    "            if improved_val:\n",
    "                best_mbic, best_sup_mbic = mbic, supp.copy()\n",
    "            best_k_for_mbic = min(best_k_for_mbic, k)\n",
    "            patience_mbic = 0\n",
    "        else:\n",
    "            patience_mbic += 1\n",
    "\n",
    "        # mBIC2\n",
    "        improved_val2 = (mbic2 < best_mbic2 - TOL)\n",
    "        improved_k2   = (k < best_k_for_mbic2)\n",
    "        if improved_val2 or improved_k2:\n",
    "            if improved_val2:\n",
    "                best_mbic2, best_sup_mbic2 = mbic2, supp.copy()\n",
    "            best_k_for_mbic2 = min(best_k_for_mbic2, k)\n",
    "            patience_mbic2 = 0\n",
    "        else:\n",
    "            patience_mbic2 += 1\n",
    "\n",
    "        if patience_mbic >= NO_IMPROVE_PATIENCE and patience_mbic2 >= NO_IMPROVE_PATIENCE:\n",
    "            break\n",
    "\n",
    "    mBIC_fin  = float(best_mbic)  if np.isfinite(best_mbic)  else np.nan\n",
    "    mBIC2_fin = float(best_mbic2) if np.isfinite(best_mbic2) else np.nan\n",
    "\n",
    "    return ModelSelResult(\n",
    "        mBIC=mBIC_fin,\n",
    "        mBIC2=mBIC2_fin,\n",
    "        model1=best_sup_mbic + 1,    # 1-basiert\n",
    "        model2=best_sup_mbic2 + 1,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa269761-ab2d-4aeb-890a-fe8879804853",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ModelSelResult' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlassonet_plus\u001b[39m(\n\u001b[32m      2\u001b[39m     y: np.ndarray,\n\u001b[32m      3\u001b[39m     X: np.ndarray,\n\u001b[32m      4\u001b[39m     model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m ) -> \u001b[43mModelSelResult\u001b[49m:\n\u001b[32m      7\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m    LassoNet mit identischen Hyperparametern wie `lassonet`, aber erweiterter\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m    mBIC-/mBIC2-gesteuerter Nachbearbeitung:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[33;03m    Gibt wie gehabt mBIC/mBIC2 und die beiden Modelle (1-basiert) zurück.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# ---- Parameter (IDENTISCH zu `lassonet`) ----\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'ModelSelResult' is not defined"
     ]
    }
   ],
   "source": [
    "def lassonet_plus(\n",
    "    y: np.ndarray,\n",
    "    X: np.ndarray,\n",
    "    model: str = \"linear\",\n",
    "    \n",
    ") -> ModelSelResult:\n",
    "    \"\"\"\n",
    "    LassoNet mit identischen Hyperparametern wie `lassonet`, aber erweiterter\n",
    "    mBIC-/mBIC2-gesteuerter Nachbearbeitung:\n",
    "      - Top-K auf Basis feature_importances_ + Feinsuche\n",
    "      - Großer Korrelations-Screen\n",
    "      - Residual-Refinement (Add, Backward-Prune, Swap) für linear & logistic\n",
    "    Gibt wie gehabt mBIC/mBIC2 und die beiden Modelle (1-basiert) zurück.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Parameter (IDENTISCH zu `lassonet`) ----\n",
    "    NO_IMPROVE_PATIENCE = 4\n",
    "    TOL = 1e-9\n",
    "    SAT_DELTA = 5\n",
    "    HIDDEN_DIMS = (4,)\n",
    "    PATH_MULTIPLIER = 1.08\n",
    "    N_ITERS = 100\n",
    "    EARLY_PATIENCE = 2\n",
    "    BATCH_SIZE = min(X.shape[0], 512)\n",
    "    RANDOM_STATE = 42\n",
    "    M = 30\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "    # ---- Vorbereitungen ----\n",
    "    model = model.lower().strip()\n",
    "    if model not in (\"linear\", \"logistic\"):\n",
    "        raise ValueError(\"lassonet_plus: model must be 'linear' or 'logistic'.\")\n",
    "    is_logistic = (model == \"logistic\")\n",
    "\n",
    "    n, p = X.shape\n",
    "    SAT_CUTOFF = min(int(p/2), int(n/2), 100)\n",
    "    K_MAX = SAT_CUTOFF\n",
    "\n",
    "    def _ll_full(supp: np.ndarray) -> tuple[float, int]:\n",
    "        \"\"\"Log-Likelihood für gegebenen Support (identisch zur Logik in `lassonet`).\"\"\"\n",
    "        k = supp.size\n",
    "        if k == 0:\n",
    "            if is_logistic:\n",
    "                p_hat = float(y.mean())\n",
    "                p_hat = min(max(p_hat, 1e-12), 1 - 1e-12)\n",
    "                ll = float((y * np.log(p_hat) + (1 - y) * np.log(1 - p_hat)).sum())\n",
    "            else:\n",
    "                sigma2_0 = max(float(np.var(y, ddof=0)), 1e-12)\n",
    "                ll = -0.5 * n * np.log(sigma2_0)\n",
    "            return ll, 0\n",
    "\n",
    "        Xk = X[:, supp]\n",
    "        if is_logistic:\n",
    "            mdl = LogisticRegression(penalty=None, solver=\"lbfgs\", max_iter=2000).fit(Xk, y.astype(int))\n",
    "            proba = np.clip(mdl.predict_proba(Xk)[:, 1], 1e-12, 1 - 1e-12)\n",
    "            ll = float((y * np.log(proba) + (1 - y) * np.log(1 - proba)).sum())\n",
    "        else:\n",
    "            mdl = LinearRegression().fit(Xk, y)\n",
    "            rss = float(((mdl.predict(Xk) - y) ** 2).sum())\n",
    "            sigma2 = max(rss / n, 1e-12)\n",
    "            ll = -0.5 * n * np.log(sigma2)\n",
    "        return ll, k\n",
    "\n",
    "    # ---- LassoNet Setup (identisch) ----\n",
    "    net_cls = LassoNetClassifier if is_logistic else LassoNetRegressor\n",
    "    net = net_cls(\n",
    "        hidden_dims=HIDDEN_DIMS,\n",
    "        path_multiplier=PATH_MULTIPLIER,\n",
    "        lambda_start=\"auto\",\n",
    "        n_iters=N_ITERS,\n",
    "        patience=EARLY_PATIENCE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        val_size=0.0,\n",
    "        random_state=RANDOM_STATE,\n",
    "        M=M,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    \n",
    "    #X_net, y_net = _prepare_for_lassonet(X, y)\n",
    "    #X_path = X_net\n",
    "    #y_fit  = y_net\n",
    "    X_path = X * float(np.sqrt(n))\n",
    "    y_fit = y.astype(int) if is_logistic else y\n",
    "\n",
    "    # ---- Pfad-Scan (identisch) ----\n",
    "    best_mbic = float(\"inf\");   best_sup_mbic = np.array([], dtype=int);   patience_mbic = 0\n",
    "    best_mbic2 = float(\"inf\");  best_sup_mbic2 = np.array([], dtype=int);  patience_mbic2 = 0\n",
    "    best_k_for_mbic  = np.inf\n",
    "    best_k_for_mbic2 = np.inf\n",
    "\n",
    "    seen_supports: set[tuple[int, ...]] = set()\n",
    "    last_state_dict = None\n",
    "\n",
    "    for _, ckpt in enumerate(net.path(X_path, y_fit)):\n",
    "        selected = getattr(ckpt, \"selected\", getattr(ckpt, \"selected_features_\", None))\n",
    "        sd = getattr(ckpt, \"state_dict\", None)\n",
    "        if sd is not None:\n",
    "            last_state_dict = sd\n",
    "        if selected is None:\n",
    "            continue\n",
    "\n",
    "        mask = np.asarray(selected, dtype=bool)\n",
    "        df = int(mask.sum())\n",
    "        if df >= SAT_CUTOFF:\n",
    "            continue\n",
    "\n",
    "        supp = np.flatnonzero(mask)\n",
    "        key = tuple(supp.tolist())\n",
    "        if key in seen_supports:\n",
    "            continue\n",
    "        seen_supports.add(key)\n",
    "\n",
    "        ll, k = _ll_full(supp)\n",
    "        mbic  = _mbic_bigstep(ll, n, k, p)\n",
    "        mbic2 = _mbic2_bigstep(ll, n, k, p)\n",
    "\n",
    "        improved_val = (mbic < best_mbic - TOL)\n",
    "        improved_k   = (k < best_k_for_mbic)\n",
    "        if improved_val or improved_k:\n",
    "            if improved_val:\n",
    "                best_mbic, best_sup_mbic = mbic, supp.copy()\n",
    "            best_k_for_mbic = min(best_k_for_mbic, k)\n",
    "            patience_mbic = 0\n",
    "        else:\n",
    "            patience_mbic += 1\n",
    "\n",
    "        improved_val2 = (mbic2 < best_mbic2 - TOL)\n",
    "        improved_k2   = (k < best_k_for_mbic2)\n",
    "        if improved_val2 or improved_k2:\n",
    "            if improved_val2:\n",
    "                best_mbic2, best_sup_mbic2 = mbic2, supp.copy()\n",
    "            best_k_for_mbic2 = min(best_k_for_mbic2, k)\n",
    "            patience_mbic2 = 0\n",
    "        else:\n",
    "            patience_mbic2 += 1\n",
    "\n",
    "        if patience_mbic >= NO_IMPROVE_PATIENCE and patience_mbic2 >= NO_IMPROVE_PATIENCE:\n",
    "            break\n",
    "\n",
    "    # ------------------------------\n",
    "    # Top-K auf Basis feature_importances_ + Feinsuche\n",
    "    # ------------------------------\n",
    "    if last_state_dict is not None:\n",
    "        try:\n",
    "            net.load_state_dict(last_state_dict)\n",
    "        except Exception:\n",
    "            try:\n",
    "                net.load(last_state_dict)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # robustes Ranking: fallback auf |X^Ty|\n",
    "    try:\n",
    "        imp_final  = np.asarray(net.feature_importances_)\n",
    "        rank_theta = np.argsort(np.abs(imp_final))[::-1]\n",
    "    except Exception:\n",
    "        rank_theta = np.argsort(np.abs(X.T @ y))[::-1]\n",
    "\n",
    "    K_hi = min(K_MAX, p)\n",
    "\n",
    "    def _score_S(S: np.ndarray):\n",
    "        ll, kk = _ll_full(S)\n",
    "        return _mbic_bigstep(ll, n, kk, p), _mbic2_bigstep(ll, n, kk, p)\n",
    "\n",
    "    def _score_K(K: int):\n",
    "        S = rank_theta[:K]\n",
    "        v1, v2 = _score_S(S)\n",
    "        return v1, v2, S\n",
    "\n",
    "    K_seed = int(best_sup_mbic.size) if best_sup_mbic.size > 0 else min(8, K_hi)\n",
    "    WINDOW = 10\n",
    "    STEP   = 2\n",
    "    K_low  = max(1, K_seed - WINDOW)\n",
    "    K_up   = min(K_seed + WINDOW, K_hi)\n",
    "\n",
    "    best_theta_mBIC,  best_theta_sup,  K_best  = best_mbic,  best_sup_mbic.copy(),  K_seed\n",
    "    best_theta_mBIC2, best_theta_sup2, K_best2 = best_mbic2, best_sup_mbic2.copy(), K_seed\n",
    "\n",
    "    for K in range(K_low, K_up + 1, STEP):\n",
    "        v1, v2, S = _score_K(K)\n",
    "        if v1 < best_theta_mBIC - TOL:\n",
    "            best_theta_mBIC, best_theta_sup,  K_best  = v1, S.copy(), K\n",
    "        if v2 < best_theta_mBIC2 - TOL:\n",
    "            best_theta_mBIC2, best_theta_sup2, K_best2 = v2, S.copy(), K\n",
    "\n",
    "    for K in range(max(1, K_best  - 3), min(K_hi, K_best  + 3) + 1):\n",
    "        v1, v2, S = _score_K(K)\n",
    "        if v1 < best_theta_mBIC - TOL:\n",
    "            best_theta_mBIC, best_theta_sup = v1, S.copy()\n",
    "\n",
    "    for K in range(max(1, K_best2 - 3), min(K_hi, K_best2 + 3) + 1):\n",
    "        v1, v2, S = _score_K(K)\n",
    "        if v2 < best_theta_mBIC2 - TOL:\n",
    "            best_theta_mBIC2, best_theta_sup2 = v2, S.copy()\n",
    "\n",
    "    if best_theta_mBIC  < best_mbic  - TOL: best_mbic,  best_sup_mbic  = best_theta_mBIC,  best_theta_sup\n",
    "    if best_theta_mBIC2 < best_mbic2 - TOL: best_mbic2, best_sup_mbic2 = best_theta_mBIC2, best_theta_sup2\n",
    "\n",
    "\n",
    "    # ------------------------------\n",
    "    # Großer Korrelations-Screen \n",
    "    # ------------------------------\n",
    "    K_screen = min(K_MAX, 70)\n",
    "    scores_glob = np.abs(X.T @ y)\n",
    "    ranked = np.argsort(scores_glob)[::-1][:K_screen]\n",
    "\n",
    "    Ks_scr = [1]\n",
    "    while Ks_scr[-1] < K_screen:\n",
    "        Ks_scr.append(min(K_screen, Ks_scr[-1] * 2))\n",
    "    if best_sup_mbic.size > 0:\n",
    "        Ks_scr.append(min(K_screen, best_sup_mbic.size))\n",
    "    Ks_scr = sorted(set(Ks_scr))\n",
    "\n",
    "    best_scr_mBIC,  best_scr_sup  = best_mbic,  best_sup_mbic\n",
    "    best_scr_mBIC2, best_scr_sup2 = best_mbic2, best_sup_mbic2\n",
    "\n",
    "    for K in Ks_scr:\n",
    "        S = ranked[:K]\n",
    "        v1, v2 = _score_S(S)\n",
    "        if v1 < best_scr_mBIC - TOL:\n",
    "            best_scr_mBIC, best_scr_sup = v1, S.copy()\n",
    "        if v2 < best_scr_mBIC2 - TOL:\n",
    "            best_scr_mBIC2, best_scr_sup2 = v2, S.copy()\n",
    "\n",
    "    if best_scr_mBIC < best_mbic - TOL:\n",
    "        best_mbic, best_sup_mbic = best_scr_mBIC, best_scr_sup\n",
    "    if best_scr_mBIC2 < best_mbic2 - TOL:\n",
    "        best_mbic2, best_sup_mbic2 = best_scr_mBIC2, best_scr_sup2\n",
    "\n",
    "    # ------------------------------\n",
    "    # Residual-Refinement (linear & logistic) – getrennt für mBIC und mBIC2\n",
    "    # ------------------------------\n",
    "    def _fit_and_residuals(S: np.ndarray):\n",
    "        if S.size == 0:\n",
    "            if is_logistic:\n",
    "                p0 = float(np.clip(y.mean(), 1e-12, 1-1e-12))\n",
    "                r  = y - p0\n",
    "                return None, r, None\n",
    "            else:\n",
    "                return None, y, None\n",
    "        Xs = X[:, S]\n",
    "        if is_logistic:\n",
    "            mdl = LogisticRegression(penalty=None, solver=\"lbfgs\", max_iter=2000).fit(Xs, y.astype(int))\n",
    "            proba = np.clip(mdl.predict_proba(Xs)[:, 1], 1e-12, 1 - 1e-12)\n",
    "            r = y - proba\n",
    "            coef = mdl.coef_.ravel()\n",
    "            return mdl, r, coef\n",
    "        else:\n",
    "            mdl = LinearRegression().fit(Xs, y)\n",
    "            r = y - mdl.predict(Xs)\n",
    "            coef = mdl.coef_\n",
    "            return mdl, r, coef\n",
    "\n",
    "    if (best_sup_mbic.size < K_MAX) or (best_sup_mbic2.size < K_MAX):\n",
    "        max_local_steps = 6\n",
    "        cand_cap_add    = min(3 * K_MAX, 240)\n",
    "        cand_cap_swap   = min(2 * K_MAX, 180)\n",
    "\n",
    "        # ===========================\n",
    "        # PASS 1: mBIC verfeinern\n",
    "        # ===========================\n",
    "        if best_sup_mbic.size < K_MAX:\n",
    "            # (0) Backward-Prune (einmalig)\n",
    "            improved = True\n",
    "            while improved and best_sup_mbic.size > 0:\n",
    "                improved = False\n",
    "                S = best_sup_mbic\n",
    "                for i in range(S.size):\n",
    "                    S_try = np.delete(S, i)\n",
    "                    v_try, _ = _score_S(S_try)  # (mBIC, mBIC2)\n",
    "                    if v_try < best_mbic - TOL:\n",
    "                        best_mbic, best_sup_mbic = v_try, S_try\n",
    "                        improved = True\n",
    "                        break  # Neustart der Schleife mit neuem Support\n",
    "\n",
    "            # (A) Greedy Add (bis keine Verbesserung)\n",
    "            for _ in range(max_local_steps):\n",
    "                _, r, _ = _fit_and_residuals(best_sup_mbic)\n",
    "                scores_r = np.abs(X.T @ r)\n",
    "                S_set = set(best_sup_mbic.tolist())\n",
    "                cand = [j for j in np.argsort(scores_r)[::-1] if j not in S_set][:cand_cap_add]\n",
    "                improved = False\n",
    "                for j in cand:\n",
    "                    S_try = np.array(sorted(S_set | {j}), dtype=int)\n",
    "                    if S_try.size > K_MAX:\n",
    "                        continue\n",
    "                    v_try, _ = _score_S(S_try)\n",
    "                    if v_try < best_mbic - TOL:\n",
    "                        best_mbic, best_sup_mbic = v_try, S_try\n",
    "                        improved = True\n",
    "                        break\n",
    "                if not improved:\n",
    "                    break\n",
    "\n",
    "            # (B) Swap (klein gehalten)\n",
    "            mdl, r, beta = _fit_and_residuals(best_sup_mbic)\n",
    "            if beta is not None and beta.size > 0:\n",
    "                order_in = np.argsort(np.abs(beta))  # schwächste zuerst\n",
    "                scores_r = np.abs(X.T @ r)\n",
    "                S_set    = set(best_sup_mbic.tolist())\n",
    "                cand_out = order_in[: min(10, beta.size)]\n",
    "                cand_in  = [j for j in np.argsort(scores_r)[::-1] if j not in S_set][:cand_cap_swap]\n",
    "\n",
    "                improved = True\n",
    "                iter_swap = 0\n",
    "                while improved and iter_swap < 4:\n",
    "                    improved = False\n",
    "                    for idx_worst in cand_out:\n",
    "                        for j in cand_in:\n",
    "                            if j in S_set:\n",
    "                                continue\n",
    "                            S_try = best_sup_mbic.copy()\n",
    "                            S_try[idx_worst] = j\n",
    "                            S_try = np.array(sorted(set(S_try.tolist())), dtype=int)\n",
    "                            if S_try.size > K_MAX:\n",
    "                                continue\n",
    "                            v_try, _ = _score_S(S_try)\n",
    "                            if v_try < best_mbic - TOL:\n",
    "                                best_mbic, best_sup_mbic = v_try, S_try\n",
    "                                S_set = set(S_try.tolist())\n",
    "                                improved = True\n",
    "                                break\n",
    "                        if improved:\n",
    "                            break\n",
    "                    iter_swap += 1\n",
    "\n",
    "        # ===========================\n",
    "        # PASS 2: mBIC2 verfeinern\n",
    "        # ===========================\n",
    "        if best_sup_mbic2.size < K_MAX:\n",
    "            # (0) Backward-Prune (einmalig)\n",
    "            improved = True\n",
    "            while improved and best_sup_mbic2.size > 0:\n",
    "                improved = False\n",
    "                S2 = best_sup_mbic2\n",
    "                for i in range(S2.size):\n",
    "                    S2_try = np.delete(S2, i)\n",
    "                    _, v2_try = _score_S(S2_try)  # (mBIC, mBIC2)\n",
    "                    if v2_try < best_mbic2 - TOL:\n",
    "                        best_mbic2, best_sup_mbic2 = v2_try, S2_try\n",
    "                        improved = True\n",
    "                        break\n",
    "\n",
    "            # (A) Greedy Add (bis keine Verbesserung)\n",
    "            for _ in range(max_local_steps):\n",
    "                _, r2, _ = _fit_and_residuals(best_sup_mbic2)\n",
    "                scores_r2 = np.abs(X.T @ r2)\n",
    "                S2_set = set(best_sup_mbic2.tolist())\n",
    "                cand2 = [j for j in np.argsort(scores_r2)[::-1] if j not in S2_set][:cand_cap_add]\n",
    "                improved = False\n",
    "                for j in cand2:\n",
    "                    S2_try = np.array(sorted(S2_set | {j}), dtype=int)\n",
    "                    if S2_try.size > K_MAX:\n",
    "                        continue\n",
    "                    _, v2_try = _score_S(S2_try)\n",
    "                    if v2_try < best_mbic2 - TOL:\n",
    "                        best_mbic2, best_sup_mbic2 = v2_try, S2_try\n",
    "                        improved = True\n",
    "                        break\n",
    "                if not improved:\n",
    "                    break\n",
    "\n",
    "            # (B) Swap (klein gehalten)\n",
    "            mdl2, r2, beta2 = _fit_and_residuals(best_sup_mbic2)\n",
    "            if beta2 is not None and beta2.size > 0:\n",
    "                order_in2 = np.argsort(np.abs(beta2))  # schwächste zuerst\n",
    "                scores_r2 = np.abs(X.T @ r2)\n",
    "                S2_set    = set(best_sup_mbic2.tolist())\n",
    "                cand_out2 = order_in2[: min(10, beta2.size)]\n",
    "                cand_in2  = [j for j in np.argsort(scores_r2)[::-1] if j not in S2_set][:cand_cap_swap]\n",
    "\n",
    "                improved = True\n",
    "                iter_swap2 = 0\n",
    "                while improved and iter_swap2 < 4:\n",
    "                    improved = False\n",
    "                    for idx_worst2 in cand_out2:\n",
    "                        for j in cand_in2:\n",
    "                            if j in S2_set:\n",
    "                                continue\n",
    "                            S2_try = best_sup_mbic2.copy()\n",
    "                            S2_try[idx_worst2] = j\n",
    "                            S2_try = np.array(sorted(set(S2_try.tolist())), dtype=int)\n",
    "                            if S2_try.size > K_MAX:\n",
    "                                continue\n",
    "                            _, v2_try = _score_S(S2_try)\n",
    "                            if v2_try < best_mbic2 - TOL:\n",
    "                                best_mbic2, best_sup_mbic2 = v2_try, S2_try\n",
    "                                S2_set = set(S2_try.tolist())\n",
    "                                improved = True\n",
    "                                break\n",
    "                        if improved:\n",
    "                            break\n",
    "                    iter_swap2 += 1\n",
    "\n",
    "\n",
    "    # Finale Werte\n",
    "    mBIC_fin  = float(best_mbic)  if np.isfinite(best_mbic)  else np.nan\n",
    "    mBIC2_fin = float(best_mbic2) if np.isfinite(best_mbic2) else np.nan\n",
    "\n",
    "    return ModelSelResult(\n",
    "        mBIC=mBIC_fin,\n",
    "        mBIC2=mBIC2_fin,\n",
    "        model1=best_sup_mbic + 1,   # 1-basiert\n",
    "        model2=best_sup_mbic2 + 1,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab23960a-6c14-450a-9be4-8af9eb67d76e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ---------- Hilfsfunktionen --------------------------------\n",
    "def _l21_norm(w: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Zeilen‑weise L2‑Norm, dann Summe (||·||₂,₁).\"\"\"\n",
    "    return torch.norm(w, dim=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49547120",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def deep2stage(\n",
    "    y: np.ndarray,\n",
    "    X: np.ndarray,\n",
    "    model: str = \"linear\",          # \"linear\" | \"logistic\"\n",
    "    h: int = 128,                    # Hidden-Dim der Autoencoder-Bottleneck-Schicht\n",
    "    stage1_epochs: int = 250,\n",
    "    stage2_epochs: int = 250,\n",
    "    batch_size: int = 512,\n",
    "    λ: float = 0.1,                 # Rekonstruktionsgewicht (Stage 1)\n",
    "    α: float | None = None,         # L2,1-Penalty (Stage 2)\n",
    "    β: float = 0,                   # Frobenius-Decay (Stage 2)\n",
    "    lr: float = 1e-3,\n",
    "    K_max: int | None = None,       # Obergrenze Support-Größe für mBIC-Suche\n",
    "    patience: int = 12,\n",
    "    device: str | torch.device = \"cpu\",\n",
    ") -> ModelSelResult:\n",
    "    \"\"\"\n",
    "    Zweiseitiges DNN-Feature-Screening ohne Validierungsset.\n",
    "    Early-Stopping basiert auf dem (gemittelten) Train-Loss je Epoche.\n",
    "    \"\"\"\n",
    "    model = model.lower().strip()\n",
    "    is_logistic = (model == \"logistic\")\n",
    "    if α is None:\n",
    "        α = 1e-7 if is_logistic else 1e-4\n",
    "    if model not in (\"linear\", \"logistic\"):\n",
    "        raise ValueError(\"deep2stage: model muss 'linear' oder 'logistic' sein.\")\n",
    "\n",
    "    n, p = X.shape\n",
    "    if K_max is None:\n",
    "        K_MAX = min(int(0.5*n), int(0.5*p), 100)\n",
    "    else:\n",
    "        K_MAX = int(K_max)\n",
    "\n",
    "    # ----- Tensors (gesamter Datensatz als 'Train') -----\n",
    "    X_t = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "    if is_logistic:\n",
    "        y_int = y.astype(int)\n",
    "        y_t = torch.tensor(y_int, dtype=torch.long, device=device)\n",
    "    else:\n",
    "        y_t = torch.tensor(y, dtype=torch.float32, device=device)\n",
    "\n",
    "    # -------------- Stage 1 – (Supervised) Autoencoder -----\n",
    "    class SAE(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.enc = nn.Sequential(\n",
    "                nn.Linear(p, 256), nn.ReLU(),\n",
    "                nn.Linear(256, h)\n",
    "            )\n",
    "            self.dec = nn.Sequential(\n",
    "                nn.Linear(h, 256), nn.ReLU(),\n",
    "                nn.Linear(256, p)\n",
    "            )\n",
    "            self.head = nn.Linear(h, 2 if is_logistic else 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            z = self.enc(x)\n",
    "            x_hat = self.dec(z)\n",
    "            y_hat = self.head(z)\n",
    "            return z, x_hat, y_hat\n",
    "\n",
    "    sae = SAE().to(device)\n",
    "    opt1 = optim.RMSprop(sae.parameters(), lr=lr)\n",
    "\n",
    "    ds = DataLoader(TensorDataset(X_t, y_t),\n",
    "                    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    best_state1, best_loss1, no_imp1 = None, float(\"inf\"), 0\n",
    "    for _ in range(stage1_epochs):\n",
    "        sae.train()\n",
    "        running, nb = 0.0, 0\n",
    "        for xb, yb in ds:\n",
    "            opt1.zero_grad()\n",
    "            z, x_hat, y_hat = sae(xb)\n",
    "            recon = nn.functional.mse_loss(x_hat, xb)\n",
    "            if is_logistic:\n",
    "                sup = nn.functional.cross_entropy(y_hat, yb)\n",
    "            else:\n",
    "                sup = nn.functional.mse_loss(y_hat.squeeze(), yb)\n",
    "            loss = sup + λ * recon\n",
    "            loss.backward()\n",
    "            opt1.step()\n",
    "            running += float(loss.item())\n",
    "            nb += 1\n",
    "        epoch_loss = running / max(nb, 1)\n",
    "        if epoch_loss < best_loss1 - 1e-6:\n",
    "            best_loss1, no_imp1 = epoch_loss, 0\n",
    "            best_state1 = {k: v.detach().clone() for k, v in sae.state_dict().items()}\n",
    "        else:\n",
    "            no_imp1 += 1\n",
    "            if no_imp1 >= patience:\n",
    "                break  # Early-Stopping Stage 1 (Train-Loss)\n",
    "\n",
    "    if best_state1 is not None:\n",
    "        sae.load_state_dict(best_state1)\n",
    "\n",
    "    # Bottleneck-Features für alle Beobachtungen + Min-Max-Norm\n",
    "    with torch.no_grad():\n",
    "        x_encode = sae.enc(X_t)\n",
    "        x_encode = (x_encode - x_encode.min(0).values) / \\\n",
    "                   (x_encode.max(0).values - x_encode.min(0).values + 1e-8)\n",
    "\n",
    "    # -------------- Stage 2 – Regularisiertes 1-Hidden-Net --\n",
    "    class Student(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.fc1 = nn.Linear(p, h)\n",
    "            self.out = nn.Linear(h, h, bias=True)\n",
    "        def forward(self, x):\n",
    "            return self.out(torch.relu(self.fc1(x)))\n",
    "\n",
    "    stu = Student().to(device)\n",
    "    opt2 = optim.RMSprop(stu.parameters(), lr=lr)\n",
    "\n",
    "    best_state2, best_loss2, no_imp2 = None, float(\"inf\"), 0\n",
    "    for _ in range(stage2_epochs):\n",
    "        stu.train()\n",
    "        opt2.zero_grad()\n",
    "        x_hat_all = stu(X_t)\n",
    "        mse = nn.functional.mse_loss(x_hat_all, x_encode)\n",
    "        l21 = _l21_norm(stu.fc1.weight)\n",
    "        frob = stu.fc1.weight.norm()**2 + stu.out.weight.norm()**2\n",
    "        loss2 = mse + α * l21 + (β / 2) * frob\n",
    "        loss2.backward()\n",
    "        opt2.step()\n",
    "\n",
    "        train_loss = float(loss2.item())\n",
    "        if train_loss < best_loss2 - 1e-6:\n",
    "            best_loss2, no_imp2 = train_loss, 0\n",
    "            best_state2 = {k: v.detach().clone() for k, v in stu.state_dict().items()}\n",
    "        else:\n",
    "            no_imp2 += 1\n",
    "            if no_imp2 >= patience:\n",
    "                break  # Early-Stopping Stage 2 (Train-Loss)\n",
    "\n",
    "    if best_state2 is not None:\n",
    "        stu.load_state_dict(best_state2)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Feature-Scores → Ranking\n",
    "    # --------------------------------------------------------\n",
    "    with torch.no_grad():\n",
    "        W1 = stu.fc1.weight                                  # h × p\n",
    "        scores = torch.sum(W1 * W1, dim=0).cpu().numpy()     # diag(W₁ᵀW₁)\n",
    "    ranked = scores.argsort()[::-1]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # mBIC / mBIC2 entlang der Top-k-Supports\n",
    "    # --------------------------------------------------------\n",
    "    best_BIC  = best_BIC2 = float(\"inf\")\n",
    "    best_sup1 = best_sup2 = np.array([], dtype=int)\n",
    "\n",
    "    n_float = float(n)\n",
    "    for k in range(0, min(K_MAX, p) + 1):\n",
    "        supp = ranked[:k]\n",
    "\n",
    "        if k == 0:\n",
    "            # ----- Log-Likelihood ohne Prädiktoren ---------------\n",
    "            if is_logistic:\n",
    "                eps = 1e-12\n",
    "                p_hat = np.clip(y_int.mean(), eps, 1 - eps)\n",
    "                ll = float((y_int * np.log(p_hat) + (1 - y_int) * np.log(1 - p_hat)).sum())\n",
    "            else:\n",
    "                sigma2_0 = np.var(y, ddof=0)\n",
    "                ll = float(-0.5 * n_float * np.log(sigma2_0 + 1e-12))\n",
    "            df = 0\n",
    "        else:\n",
    "            Xk = X[:, supp]\n",
    "            if is_logistic:\n",
    "                try:\n",
    "                    mdl = LogisticRegression(penalty=None, solver=\"lbfgs\", max_iter=2000).fit(Xk, y_int)\n",
    "                except Exception:\n",
    "                    # Fallback für ältere sklearn-Versionen\n",
    "                    mdl = LogisticRegression(penalty=\"l2\", C=1e12, solver=\"lbfgs\", max_iter=2000).fit(Xk, y_int)\n",
    "                # LL via proba + Clipping (deine Variante)\n",
    "                class1_col = int(np.where(mdl.classes_ == 1)[0][0])\n",
    "                proba = mdl.predict_proba(Xk)[:, class1_col]\n",
    "                proba = np.clip(proba, 1e-12, 1 - 1e-12)\n",
    "                ll = float((y_int * np.log(proba) + (1 - y_int) * np.log(1 - proba)).sum())\n",
    "            else:\n",
    "                mdl = LinearRegression().fit(Xk, y)\n",
    "                rss = float(((mdl.predict(Xk) - y) ** 2).sum())\n",
    "                sigma2 = rss / n_float\n",
    "                ll = float(-0.5 * n_float * np.log(sigma2 + 1e-12))\n",
    "            df = k\n",
    "\n",
    "        mBIC  = _mbic_bigstep(ll, n, k, p)\n",
    "        mBIC2 = _mbic2_bigstep(ll, n, k, p)\n",
    "\n",
    "        if mBIC < best_BIC:\n",
    "            best_BIC, best_sup1 = mBIC, supp.copy()\n",
    "        if mBIC2 < best_BIC2:\n",
    "            best_BIC2, best_sup2 = mBIC2, supp.copy()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Rückgabe (1-basiert)\n",
    "    # --------------------------------------------------------\n",
    "    return ModelSelResult(\n",
    "        mBIC  = float(best_BIC),\n",
    "        mBIC2 = float(best_BIC2),\n",
    "        model1 = best_sup1 + 1,\n",
    "        model2 = best_sup2 + 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f314c55b-ca83-45b7-8205-fa3f657dd5b0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def deep2stage_plus(\n",
    "    y: np.ndarray,\n",
    "    X: np.ndarray,\n",
    "    model: str = \"linear\",          # \"linear\" | \"logistic\"\n",
    "    h: int = 128,                    # Hidden-Dim der Autoencoder-Bottleneck-Schicht\n",
    "    stage1_epochs: int = 250,\n",
    "    stage2_epochs: int = 250,\n",
    "    batch_size: int = 512,\n",
    "    λ: float = 0.1,                 # Rekonstruktionsgewicht (Stage 1)\n",
    "    α: float | None = None,         # L2,1-Penalty (Stage 2)\n",
    "    β: float = 0,                   # Frobenius-Decay (Stage 2)\n",
    "    lr: float = 1e-3,\n",
    "    K_max: int | None = None,       # Obergrenze Support-Größe für mBIC-Suche\n",
    "    patience: int = 12,\n",
    "    device: str | torch.device = \"cpu\",\n",
    ") -> ModelSelResult:\n",
    "    \"\"\"\n",
    "    deep2stage + (Top-K Feinsuche, Korrelations-Screen, Residual-Refinement).\n",
    "    Early-Stopping bleibt auf Train-Loss je Epoche.\n",
    "    \"\"\"\n",
    "    model = model.lower().strip()\n",
    "    is_logistic = (model == \"logistic\")\n",
    "    if α is None:\n",
    "        α = 1e-7 if is_logistic else 1e-4\n",
    "    if model not in (\"linear\", \"logistic\"):\n",
    "        raise ValueError(\"deep2stage_plus: model muss 'linear' oder 'logistic' sein.\")\n",
    "\n",
    "    n, p = X.shape\n",
    "    if K_max is None:\n",
    "        K_MAX = min(int(0.5*n), int(0.5*p), 100)\n",
    "    else:\n",
    "        K_MAX = int(K_max)\n",
    "    K_hi = min(K_MAX, p)\n",
    "    TOL = 1e-9\n",
    "\n",
    "    # ----- Tensors -----\n",
    "    X_t = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "    if is_logistic:\n",
    "        y_int = y.astype(int)\n",
    "        y_t = torch.tensor(y_int, dtype=torch.long, device=device)\n",
    "    else:\n",
    "        y_t = torch.tensor(y, dtype=torch.float32, device=device)\n",
    "\n",
    "    # -------------- Stage 1 – (Supervised) Autoencoder -----\n",
    "    class SAE(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.enc = nn.Sequential(\n",
    "                nn.Linear(p, 256), nn.ReLU(),\n",
    "                nn.Linear(256, h)\n",
    "            )\n",
    "            self.dec = nn.Sequential(\n",
    "                nn.Linear(h, 256), nn.ReLU(),\n",
    "                nn.Linear(256, p)\n",
    "            )\n",
    "            self.head = nn.Linear(h, 2 if is_logistic else 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            z = self.enc(x)\n",
    "            x_hat = self.dec(z)\n",
    "            y_hat = self.head(z)\n",
    "            return z, x_hat, y_hat\n",
    "\n",
    "    sae = SAE().to(device)\n",
    "    opt1 = optim.RMSprop(sae.parameters(), lr=lr)\n",
    "    ds = DataLoader(TensorDataset(X_t, y_t),\n",
    "                    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    best_state1, best_loss1, no_imp1 = None, float(\"inf\"), 0\n",
    "    for _ in range(stage1_epochs):\n",
    "        sae.train()\n",
    "        running, nb = 0.0, 0\n",
    "        for xb, yb in ds:\n",
    "            opt1.zero_grad()\n",
    "            z, x_hat, y_hat = sae(xb)\n",
    "            recon = nn.functional.mse_loss(x_hat, xb)\n",
    "            if is_logistic:\n",
    "                sup = nn.functional.cross_entropy(y_hat, yb)\n",
    "            else:\n",
    "                sup = nn.functional.mse_loss(y_hat.squeeze(), yb)\n",
    "            loss = sup + λ * recon\n",
    "            loss.backward()\n",
    "            opt1.step()\n",
    "            running += float(loss.item()); nb += 1\n",
    "        epoch_loss = running / max(nb, 1)\n",
    "        if epoch_loss < best_loss1 - 1e-6:\n",
    "            best_loss1, no_imp1 = epoch_loss, 0\n",
    "            best_state1 = {k: v.detach().clone() for k, v in sae.state_dict().items()}\n",
    "        else:\n",
    "            no_imp1 += 1\n",
    "            if no_imp1 >= patience:\n",
    "                break\n",
    "\n",
    "    if best_state1 is not None:\n",
    "        sae.load_state_dict(best_state1)\n",
    "\n",
    "    # Bottleneck-Features (Min-Max-Norm)\n",
    "    with torch.no_grad():\n",
    "        x_encode = sae.enc(X_t)\n",
    "        x_encode = (x_encode - x_encode.min(0).values) / \\\n",
    "                   (x_encode.max(0).values - x_encode.min(0).values + 1e-8)\n",
    "\n",
    "    # -------------- Stage 2 – Regularisiertes 1-Hidden-Net --\n",
    "    class Student(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.fc1 = nn.Linear(p, h)\n",
    "            self.out = nn.Linear(h, h, bias=True)\n",
    "        def forward(self, x):\n",
    "            return self.out(torch.relu(self.fc1(x)))\n",
    "\n",
    "    stu = Student().to(device)\n",
    "    opt2 = optim.RMSprop(stu.parameters(), lr=lr)\n",
    "\n",
    "    best_state2, best_loss2, no_imp2 = None, float(\"inf\"), 0\n",
    "    for _ in range(stage2_epochs):\n",
    "        stu.train()\n",
    "        opt2.zero_grad()\n",
    "        x_hat_all = stu(X_t)\n",
    "        mse = nn.functional.mse_loss(x_hat_all, x_encode)\n",
    "        l21 = _l21_norm(stu.fc1.weight)\n",
    "        frob = stu.fc1.weight.norm()**2 + stu.out.weight.norm()**2\n",
    "        loss2 = mse + α * l21 + (β / 2) * frob\n",
    "        loss2.backward()\n",
    "        opt2.step()\n",
    "\n",
    "        train_loss = float(loss2.item())\n",
    "        if train_loss < best_loss2 - 1e-6:\n",
    "            best_loss2, no_imp2 = train_loss, 0\n",
    "            best_state2 = {k: v.detach().clone() for k, v in stu.state_dict().items()}\n",
    "        else:\n",
    "            no_imp2 += 1\n",
    "            if no_imp2 >= patience:\n",
    "                break\n",
    "\n",
    "    if best_state2 is not None:\n",
    "        stu.load_state_dict(best_state2)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Feature-Scores → Ranking (Importances)\n",
    "    # --------------------------------------------------------\n",
    "    with torch.no_grad():\n",
    "        W1 = stu.fc1.weight                                  # h × p\n",
    "        scores = torch.sum(W1 * W1, dim=0).cpu().numpy()     # diag(W₁ᵀW₁)\n",
    "    ranked = scores.argsort()[::-1]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # (Baseline) mBIC / mBIC2 entlang der Top-k-Supports\n",
    "    # --------------------------------------------------------\n",
    "    def _ll_full(supp: np.ndarray) -> tuple[float, int]:\n",
    "        k = supp.size\n",
    "        if k == 0:\n",
    "            if is_logistic:\n",
    "                eps = 1e-12\n",
    "                p_hat = float(np.clip(y.mean(), eps, 1 - eps))\n",
    "                ll = float((y * np.log(p_hat) + (1 - y) * np.log(1 - p_hat)).sum())\n",
    "            else:\n",
    "                sigma2_0 = max(float(np.var(y, ddof=0)), 1e-12)\n",
    "                ll = -0.5 * n * np.log(sigma2_0)\n",
    "            return ll, 0\n",
    "        Xk = X[:, supp]\n",
    "        if is_logistic:\n",
    "            try:\n",
    "                mdl = LogisticRegression(penalty=None, solver=\"lbfgs\", max_iter=2000).fit(Xk, y.astype(int))\n",
    "            except Exception:\n",
    "                mdl = LogisticRegression(penalty=\"l2\", C=1e12, solver=\"lbfgs\", max_iter=2000).fit(Xk, y.astype(int))\n",
    "            proba = np.clip(mdl.predict_proba(Xk)[:, 1], 1e-12, 1 - 1e-12)\n",
    "            ll = float((y * np.log(proba) + (1 - y) * np.log(1 - proba)).sum())\n",
    "        else:\n",
    "            mdl = LinearRegression().fit(Xk, y)\n",
    "            rss = float(((mdl.predict(Xk) - y) ** 2).sum())\n",
    "            sigma2 = max(rss / n, 1e-12)\n",
    "            ll = -0.5 * n * np.log(sigma2)\n",
    "        return ll, k\n",
    "\n",
    "    best_mbic  = float(\"inf\"); best_sup_mbic  = np.array([], dtype=int)\n",
    "    best_mbic2 = float(\"inf\"); best_sup_mbic2 = np.array([], dtype=int)\n",
    "\n",
    "    for k in range(0, min(K_MAX, p) + 1):\n",
    "        supp = ranked[:k]\n",
    "        ll, df = _ll_full(supp)\n",
    "        mbic  = _mbic_bigstep(ll, n, df, p)\n",
    "        mbic2 = _mbic2_bigstep(ll, n, df, p)\n",
    "        if mbic < best_mbic:\n",
    "            best_mbic, best_sup_mbic = mbic, supp.copy()\n",
    "        if mbic2 < best_mbic2:\n",
    "            best_mbic2, best_sup_mbic2 = mbic2, supp.copy()\n",
    "\n",
    "    # ========================================================\n",
    "    # Top-K auf Basis Importances + Feinsuche\n",
    "    # (feature_importances_ → hier: scores aus W1; Fallback: |X^Ty|)\n",
    "    # ========================================================\n",
    "    try:\n",
    "        imp_final = np.asarray(scores)\n",
    "        rank_theta = np.argsort(np.abs(imp_final))[::-1]\n",
    "    except Exception:\n",
    "        rank_theta = np.argsort(np.abs(X.T @ (y if not is_logistic else y.astype(float))))[::-1]\n",
    "\n",
    "    def _score_S(S: np.ndarray):\n",
    "        ll, kk = _ll_full(S)\n",
    "        return _mbic_bigstep(ll, n, kk, p), _mbic2_bigstep(ll, n, kk, p)\n",
    "\n",
    "    def _score_K(K: int):\n",
    "        S = rank_theta[:K]\n",
    "        v1, v2 = _score_S(S)\n",
    "        return v1, v2, S\n",
    "\n",
    "    K_seed = int(best_sup_mbic.size) if best_sup_mbic.size > 0 else min(8, K_hi)\n",
    "    WINDOW, STEP = 10, 2\n",
    "    K_low  = max(1, K_seed - WINDOW)\n",
    "    K_up   = min(K_seed + WINDOW, K_hi)\n",
    "\n",
    "    best_theta_mBIC,  best_theta_sup,  K_best  = best_mbic,  best_sup_mbic.copy(),  K_seed\n",
    "    best_theta_mBIC2, best_theta_sup2, K_best2 = best_mbic2, best_sup_mbic2.copy(), K_seed\n",
    "\n",
    "    for K in range(K_low, K_up + 1, STEP):\n",
    "        v1, v2, S = _score_K(K)\n",
    "        if v1 < best_theta_mBIC - TOL:\n",
    "            best_theta_mBIC, best_theta_sup,  K_best  = v1, S.copy(), K\n",
    "        if v2 < best_theta_mBIC2 - TOL:\n",
    "            best_theta_mBIC2, best_theta_sup2, K_best2 = v2, S.copy(), K\n",
    "\n",
    "    for K in range(max(1, K_best  - 3), min(K_hi, K_best  + 3) + 1):\n",
    "        v1, v2, S = _score_K(K)\n",
    "        if v1 < best_theta_mBIC - TOL:\n",
    "            best_theta_mBIC, best_theta_sup = v1, S.copy()\n",
    "\n",
    "    for K in range(max(1, K_best2 - 3), min(K_hi, K_best2 + 3) + 1):\n",
    "        v1, v2, S = _score_K(K)\n",
    "        if v2 < best_theta_mBIC2 - TOL:\n",
    "            best_theta_mBIC2, best_theta_sup2 = v2, S.copy()\n",
    "\n",
    "    # getrennt zurückspielen\n",
    "    if best_theta_mBIC  < best_mbic  - TOL: best_mbic,  best_sup_mbic  = best_theta_mBIC,  best_theta_sup\n",
    "    if best_theta_mBIC2 < best_mbic2 - TOL: best_mbic2, best_sup_mbic2 = best_theta_mBIC2, best_theta_sup2\n",
    "\n",
    "    # ========================================================\n",
    "    # Großer Korrelations-Screen\n",
    "    # ========================================================\n",
    "    K_screen = min(K_MAX, 70)\n",
    "    scores_glob = np.abs(X.T @ (y if not is_logistic else y.astype(float)))\n",
    "    ranked_scr = np.argsort(scores_glob)[::-1][:K_screen]\n",
    "\n",
    "    Ks_scr = [1]\n",
    "    while Ks_scr[-1] < K_screen:\n",
    "        Ks_scr.append(min(K_screen, Ks_scr[-1] * 2))\n",
    "    if best_sup_mbic.size > 0:\n",
    "        Ks_scr.append(min(K_screen, best_sup_mbic.size))\n",
    "    Ks_scr = sorted(set(Ks_scr))\n",
    "\n",
    "    best_scr_mBIC,  best_scr_sup  = best_mbic,  best_sup_mbic\n",
    "    best_scr_mBIC2, best_scr_sup2 = best_mbic2, best_sup_mbic2\n",
    "\n",
    "    for K in Ks_scr:\n",
    "        S = ranked_scr[:K]\n",
    "        v1, v2 = _score_S(S)\n",
    "        if v1 < best_scr_mBIC - TOL:\n",
    "            best_scr_mBIC, best_scr_sup = v1, S.copy()\n",
    "        if v2 < best_scr_mBIC2 - TOL:\n",
    "            best_scr_mBIC2, best_scr_sup2 = v2, S.copy()\n",
    "\n",
    "    if best_scr_mBIC < best_mbic - TOL:\n",
    "        best_mbic, best_sup_mbic = best_scr_mBIC, best_scr_sup\n",
    "    if best_scr_mBIC2 < best_mbic2 - TOL:\n",
    "        best_mbic2, best_sup_mbic2 = best_scr_mBIC2, best_scr_sup2\n",
    "\n",
    "    # ------------------------------\n",
    "    # Residual-Refinement (linear & logistic) – getrennt für mBIC und mBIC2\n",
    "    # ------------------------------\n",
    "    def _fit_and_residuals(S: np.ndarray):\n",
    "        if S.size == 0:\n",
    "            if is_logistic:\n",
    "                p0 = float(np.clip(y.mean(), 1e-12, 1-1e-12))\n",
    "                r  = y - p0\n",
    "                return None, r, None\n",
    "            else:\n",
    "                return None, y, None\n",
    "        Xs = X[:, S]\n",
    "        if is_logistic:\n",
    "            mdl = LogisticRegression(penalty=None, solver=\"lbfgs\", max_iter=2000).fit(Xs, y.astype(int))\n",
    "            proba = np.clip(mdl.predict_proba(Xs)[:, 1], 1e-12, 1 - 1e-12)\n",
    "            r = y - proba\n",
    "            coef = mdl.coef_.ravel()\n",
    "            return mdl, r, coef\n",
    "        else:\n",
    "            mdl = LinearRegression().fit(Xs, y)\n",
    "            r = y - mdl.predict(Xs)\n",
    "            coef = mdl.coef_\n",
    "            return mdl, r, coef\n",
    "\n",
    "    if (best_sup_mbic.size < K_MAX) or (best_sup_mbic2.size < K_MAX):\n",
    "        max_local_steps = 6\n",
    "        cand_cap_add    = min(3 * K_MAX, 240)\n",
    "        cand_cap_swap   = min(2 * K_MAX, 180)\n",
    "\n",
    "        # ===========================\n",
    "        # PASS 1: mBIC verfeinern\n",
    "        # ===========================\n",
    "        if best_sup_mbic.size < K_MAX:\n",
    "            # (0) Backward-Prune (einmalig)\n",
    "            improved = True\n",
    "            while improved and best_sup_mbic.size > 0:\n",
    "                improved = False\n",
    "                S = best_sup_mbic\n",
    "                for i in range(S.size):\n",
    "                    S_try = np.delete(S, i)\n",
    "                    v_try, _ = _score_S(S_try)  # (mBIC, mBIC2)\n",
    "                    if v_try < best_mbic - TOL:\n",
    "                        best_mbic, best_sup_mbic = v_try, S_try\n",
    "                        improved = True\n",
    "                        break  # Neustart der Schleife mit neuem Support\n",
    "\n",
    "            # (A) Greedy Add (bis keine Verbesserung)\n",
    "            for _ in range(max_local_steps):\n",
    "                _, r, _ = _fit_and_residuals(best_sup_mbic)\n",
    "                scores_r = np.abs(X.T @ r)\n",
    "                S_set = set(best_sup_mbic.tolist())\n",
    "                cand = [j for j in np.argsort(scores_r)[::-1] if j not in S_set][:cand_cap_add]\n",
    "                improved = False\n",
    "                for j in cand:\n",
    "                    S_try = np.array(sorted(S_set | {j}), dtype=int)\n",
    "                    if S_try.size > K_MAX:\n",
    "                        continue\n",
    "                    v_try, _ = _score_S(S_try)\n",
    "                    if v_try < best_mbic - TOL:\n",
    "                        best_mbic, best_sup_mbic = v_try, S_try\n",
    "                        improved = True\n",
    "                        break\n",
    "                if not improved:\n",
    "                    break\n",
    "\n",
    "            # (B) Swap (klein gehalten)\n",
    "            mdl, r, beta = _fit_and_residuals(best_sup_mbic)\n",
    "            if beta is not None and beta.size > 0:\n",
    "                order_in = np.argsort(np.abs(beta))  # schwächste zuerst\n",
    "                scores_r = np.abs(X.T @ r)\n",
    "                S_set    = set(best_sup_mbic.tolist())\n",
    "                cand_out = order_in[: min(10, beta.size)]\n",
    "                cand_in  = [j for j in np.argsort(scores_r)[::-1] if j not in S_set][:cand_cap_swap]\n",
    "\n",
    "                improved = True\n",
    "                iter_swap = 0\n",
    "                while improved and iter_swap < 4:\n",
    "                    improved = False\n",
    "                    for idx_worst in cand_out:\n",
    "                        for j in cand_in:\n",
    "                            if j in S_set:\n",
    "                                continue\n",
    "                            S_try = best_sup_mbic.copy()\n",
    "                            S_try[idx_worst] = j\n",
    "                            S_try = np.array(sorted(set(S_try.tolist())), dtype=int)\n",
    "                            if S_try.size > K_MAX:\n",
    "                                continue\n",
    "                            v_try, _ = _score_S(S_try)\n",
    "                            if v_try < best_mbic - TOL:\n",
    "                                best_mbic, best_sup_mbic = v_try, S_try\n",
    "                                S_set = set(S_try.tolist())\n",
    "                                improved = True\n",
    "                                break\n",
    "                        if improved:\n",
    "                            break\n",
    "                    iter_swap += 1\n",
    "\n",
    "        # ===========================\n",
    "        # PASS 2: mBIC2 verfeinern\n",
    "        # ===========================\n",
    "        if best_sup_mbic2.size < K_MAX:\n",
    "            # (0) Backward-Prune (einmalig)\n",
    "            improved = True\n",
    "            while improved and best_sup_mbic2.size > 0:\n",
    "                improved = False\n",
    "                S2 = best_sup_mbic2\n",
    "                for i in range(S2.size):\n",
    "                    S2_try = np.delete(S2, i)\n",
    "                    _, v2_try = _score_S(S2_try)  # (mBIC, mBIC2)\n",
    "                    if v2_try < best_mbic2 - TOL:\n",
    "                        best_mbic2, best_sup_mbic2 = v2_try, S2_try\n",
    "                        improved = True\n",
    "                        break\n",
    "\n",
    "            # (A) Greedy Add (bis keine Verbesserung)\n",
    "            for _ in range(max_local_steps):\n",
    "                _, r2, _ = _fit_and_residuals(best_sup_mbic2)\n",
    "                scores_r2 = np.abs(X.T @ r2)\n",
    "                S2_set = set(best_sup_mbic2.tolist())\n",
    "                cand2 = [j for j in np.argsort(scores_r2)[::-1] if j not in S2_set][:cand_cap_add]\n",
    "                improved = False\n",
    "                for j in cand2:\n",
    "                    S2_try = np.array(sorted(S2_set | {j}), dtype=int)\n",
    "                    if S2_try.size > K_MAX:\n",
    "                        continue\n",
    "                    _, v2_try = _score_S(S2_try)\n",
    "                    if v2_try < best_mbic2 - TOL:\n",
    "                        best_mbic2, best_sup_mbic2 = v2_try, S2_try\n",
    "                        improved = True\n",
    "                        break\n",
    "                if not improved:\n",
    "                    break\n",
    "\n",
    "            # (B) Swap (klein gehalten)\n",
    "            mdl2, r2, beta2 = _fit_and_residuals(best_sup_mbic2)\n",
    "            if beta2 is not None and beta2.size > 0:\n",
    "                order_in2 = np.argsort(np.abs(beta2))  # schwächste zuerst\n",
    "                scores_r2 = np.abs(X.T @ r2)\n",
    "                S2_set    = set(best_sup_mbic2.tolist())\n",
    "                cand_out2 = order_in2[: min(10, beta2.size)]\n",
    "                cand_in2  = [j for j in np.argsort(scores_r2)[::-1] if j not in S2_set][:cand_cap_swap]\n",
    "\n",
    "                improved = True\n",
    "                iter_swap2 = 0\n",
    "                while improved and iter_swap2 < 4:\n",
    "                    improved = False\n",
    "                    for idx_worst2 in cand_out2:\n",
    "                        for j in cand_in2:\n",
    "                            if j in S2_set:\n",
    "                                continue\n",
    "                            S2_try = best_sup_mbic2.copy()\n",
    "                            S2_try[idx_worst2] = j\n",
    "                            S2_try = np.array(sorted(set(S2_try.tolist())), dtype=int)\n",
    "                            if S2_try.size > K_MAX:\n",
    "                                continue\n",
    "                            _, v2_try = _score_S(S2_try)\n",
    "                            if v2_try < best_mbic2 - TOL:\n",
    "                                best_mbic2, best_sup_mbic2 = v2_try, S2_try\n",
    "                                S2_set = set(S2_try.tolist())\n",
    "                                improved = True\n",
    "                                break\n",
    "                        if improved:\n",
    "                            break\n",
    "                    iter_swap2 += 1\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Rückgabe (1-basiert)\n",
    "    # --------------------------------------------------------\n",
    "    mBIC_fin  = float(best_mbic)  if np.isfinite(best_mbic)  else np.nan\n",
    "    mBIC2_fin = float(best_mbic2) if np.isfinite(best_mbic2) else np.nan\n",
    "\n",
    "    return ModelSelResult(\n",
    "        mBIC  = mBIC_fin,\n",
    "        mBIC2 = mBIC2_fin,\n",
    "        model1 = best_sup_mbic + 1,\n",
    "        model2 = best_sup_mbic2 + 1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ffbdf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Öffentliche API\n",
    "__all__ = [\n",
    "    \"ModelSelResult\",\n",
    "    \"stepwise_plain\",\n",
    "    \"stepwise_reduced\",\n",
    "    \"stepwise_ff\",\n",
    "    \"L0opt_CD\",\n",
    "    \"L0opt_CDPSI\",\n",
    "    \"Select_GSDAR\",\n",
    "    \"lassonet\",\n",
    "    \"lassonet_plus\",\n",
    "    \"deep2stage\", \n",
    "    \"deep2stage_plus\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc35024-ed66-4d88-b672-5c1a85d3aeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f3993-c402-4fca-a7ce-3fc224418d55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
