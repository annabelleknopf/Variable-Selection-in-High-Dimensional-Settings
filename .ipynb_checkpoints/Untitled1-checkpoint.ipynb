{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df3d262b-fc74-430d-9f84-16b8c309f895",
   "metadata": {},
   "source": [
    "# Korrelatiosstruktur der Daten in Simulation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c263f627-e282-466c-8c32-3cedaec264c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from time import time\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng, Generator\n",
    "from scipy.special import expit as sigmoid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import scale\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "\n",
    "# Load SNP data\n",
    "r_data_path = os.path.join(\"Data\", \"SNP_data.RData\")\n",
    "if not os.path.exists(r_data_path):\n",
    "    raise FileNotFoundError(f\"{r_data_path} not found – please provide the file.\")\n",
    "\n",
    "r_objects = pyreadr.read_r(r_data_path)\n",
    "X_SNP = r_objects[\"X_SNP\"].to_numpy()\n",
    "#Cluster_list = r_objects[\"Cluster.list\"]  # list of 1‑based vectors (R style)\n",
    "import pandas as _pd  # local import\n",
    "_df: _pd.DataFrame = r_objects[\"Cluster.df\"]\n",
    "\n",
    "import pandas as _pd  # local import\n",
    "_df: _pd.DataFrame = r_objects[\"Cluster.df\"]\n",
    "# first column = cluster ID, second column = SNP index (1‑based)\n",
    "clust_col, snp_col = _df.columns[:2]\n",
    "_grouped = _df.groupby(clust_col)[snp_col]\n",
    "Cluster_list = [grp.values for _, grp in _grouped]\n",
    "#print(f\"→ Converted Cluster.df with {len(Cluster_list)} clusters.\")\n",
    "\n",
    "# Convert clusters (1‑based R indices) to 0‑based NumPy arrays (1‑based R indices) to 0‑based NumPy arrays\n",
    "Cluster_list_py = [np.asarray(cl, dtype=int) - 1 for cl in Cluster_list]\n",
    "\n",
    "n, p = X_SNP.shape\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X = scaler.fit_transform(X_SNP) / np.sqrt(n)\n",
    "\n",
    "# SNP categories\n",
    "Singletons = np.concatenate([cl for cl in Cluster_list_py if len(cl) == 1]).astype(int)\n",
    "LargerClusters = [cl.astype(int) for cl in Cluster_list_py if len(cl) >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f34eb967-32b8-4278-a012-9c4e59596606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 1000, p = 7297\n",
      "Anzahl Singletons: 3075\n",
      "Anzahl Cluster (>= 2): 1533\n",
      "Anzahl Large-Cluster (>= 5): 134\n"
     ]
    }
   ],
   "source": [
    "# Dimensionen und Anzahl Cluster\n",
    "\n",
    "num_singletons      = sum(1 for cl in Cluster_list_py if len(cl) == 1)\n",
    "num_clusters_ge2    = sum(1 for cl in Cluster_list_py if len(cl) >= 2)\n",
    "num_large_clusters  = sum(1 for cl in Cluster_list_py if len(cl) >= 5)\n",
    "\n",
    "print(f\"n = {n}, p = {p}\")\n",
    "print(f\"Anzahl Singletons: {num_singletons}\")\n",
    "print(f\"Anzahl Cluster (>= 2): {num_clusters_ge2}\")\n",
    "print(f\"Anzahl Large-Cluster (>= 5): {num_large_clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c60e1ee-4621-4801-8234-5db42868ff60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betragskorrelationen |r|:  min = 0.000000,  mean = 0.036704,  max = 0.978502\n",
      "median = 0.028314, Q95 = 0.097908\n"
     ]
    }
   ],
   "source": [
    "# Korrelation Singeltons\n",
    "\n",
    "R = X[:, Singletons].T @ X             \n",
    "# Selbstkorrelationen (Singleton i mit sich selbst) ausschließen\n",
    "R = R.astype(float)\n",
    "R[np.arange(len(Singletons)), Singletons] = np.nan\n",
    "\n",
    "# Signierte Korrelationen\n",
    "min_corr  = np.nanmin(R)\n",
    "mean_corr = np.nanmean(R)\n",
    "max_corr  = np.nanmax(R)\n",
    "\n",
    "# Betragskorrelationen\n",
    "A = np.abs(R)\n",
    "min_abs  = np.nanmin(A)\n",
    "mean_abs = np.nanmean(A)\n",
    "max_abs  = np.nanmax(A)\n",
    "\n",
    "# Robustere Lage-/Tail-Kennzahlen (empfohlen)\n",
    "median_abs = np.nanmedian(A)\n",
    "q95_abs    = np.nanquantile(A, 0.95)\n",
    "\n",
    "print(f\"Betragskorrelationen |r|:  min = {min_abs:.6f},  mean = {mean_abs:.6f},  max = {max_abs:.6f}\")\n",
    "print(f\"median = {median_abs:.6f}, Q95 = {q95_abs:.6f}\")\n",
    "\n",
    "# 95 % aller betrachteten Betragskorrelationen (|r|) der Singletons zu allen anderen SNPs sind ≤ 0.1. \n",
    "# Die restlichen 5 % können größer sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ecc2319-7371-45b3-bac8-d94ac75a22ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clumping Schwelle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01619dee-b480-4b38-80d0-80295b68ff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation within the clusters: |r|  median=0.7269, mean=0.7287, Q95=0.9851, max=1.0000, min=0.0633\n"
     ]
    }
   ],
   "source": [
    "# Korrelation Cluster\n",
    "#innerhalb des Clusters\n",
    "\n",
    "vals = []\n",
    "for cl in LargerClusters:\n",
    "    m = len(cl)\n",
    "    if m < 2: \n",
    "        continue\n",
    "    subX = X[:, cl]\n",
    "    R = subX.T @ subX                   # (m, m)\n",
    "    tri = np.triu_indices(m, 1)\n",
    "    vals.append(np.abs(R[tri]))\n",
    "\n",
    "vals = np.concatenate(vals) if vals else np.array([])\n",
    "\n",
    "if vals.size:\n",
    "    print(f\"Correlation within the clusters: |r|  median={np.median(vals):.4f}, mean={vals.mean():.4f}, \"\n",
    "          f\"Q95={np.quantile(vals, 0.95):.4f}, max={vals.max():.4f}, min={vals.min():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d492c34-94f8-46f5-8259-11803ca5c7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leakage |r|: median=0.0324, mean=0.0441, Q95=0.1241, max=0.9756\n"
     ]
    }
   ],
   "source": [
    "# Korrelation Cluster\n",
    "# außerhalb des Clusters\n",
    "\n",
    "all_idx = np.arange(p)\n",
    "leak = np.concatenate([\n",
    "    np.abs((X[:, cl].T @ X[:, np.setdiff1d(all_idx, cl, assume_unique=True)])).ravel()\n",
    "    for cl in LargerClusters if len(cl) > 0\n",
    "]) if LargerClusters else np.array([])\n",
    "\n",
    "\n",
    "print(f\"Leakage |r|: median={np.median(leak):.4f}, mean={leak.mean():.4f}, \"\n",
    "      f\"Q95={np.quantile(leak, 0.95):.4f}, max={leak.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8caaa594-aab8-4503-85c8-33a32c5e2142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anteil lückenloser LargeClusters: 0.037\n",
      "Median coverage: 0.390\n",
      "Gaps (Indexraum): median=2.0, Q95=11.0, max=79.0\n",
      "Anteil gap=1:   0.353\n",
      "Anteil gap<=5:  0.831\n",
      "Anteil gap<=10: 0.945\n"
     ]
    }
   ],
   "source": [
    "# Lage der SNPs der Cluster\n",
    "\n",
    "rows, gaps_all = [], []\n",
    "for cid, cl in enumerate(LargerClusters, start=1):\n",
    "    idx = np.sort(np.asarray(cl, dtype=int))\n",
    "    m = idx.size\n",
    "    gaps = np.diff(idx)                    # Index-Abstände innerhalb des Clusters\n",
    "    gaps_all.append(gaps)\n",
    "    span = int(idx[-1] - idx[0])           # Spannweite im Indexraum\n",
    "    coverage = m / (span + 1) if span >= 0 else np.nan\n",
    "    rows.append(dict(\n",
    "        cluster_id=cid, size=m,\n",
    "        start=int(idx[0]), end=int(idx[-1]),\n",
    "        span=span, coverage=float(coverage),\n",
    "        contiguous=bool(np.all(gaps == 1))\n",
    "    ))\n",
    "\n",
    "pos_idx_df = pd.DataFrame(rows).sort_values([\"size\",\"span\"], ascending=[False, True])\n",
    "\n",
    "# Zusammenfassung\n",
    "gaps_all = np.concatenate(gaps_all) if len(gaps_all) else np.array([])\n",
    "print(f\"Anteil lückenloser LargeClusters: {pos_idx_df['contiguous'].mean():.3f}\")\n",
    "print(f\"Median coverage: {pos_idx_df['coverage'].median():.3f}\")\n",
    "if gaps_all.size:\n",
    "    print(f\"Gaps (Indexraum): median={np.median(gaps_all):.1f}, \"    # Gap = Abstand zum nächsten SNP im selben Cluster\n",
    "          f\"Q95={np.quantile(gaps_all, 0.95):.1f}, max={np.max(gaps_all):.1f}\")\n",
    "\n",
    "\n",
    "# Wie häufig liegen Cluster-Paare „nah beieinander“?\n",
    "\n",
    "near1=near5=near10=0; total=0\n",
    "for cl in LargerClusters:\n",
    "    idx=np.sort(cl); g=np.diff(idx)\n",
    "    total += g.size\n",
    "    near1  += np.sum(g==1)\n",
    "    near5  += np.sum(g<=5)\n",
    "    near10 += np.sum(g<=10)\n",
    "print(f\"Anteil gap=1:   {near1/total:.3f}\")\n",
    "print(f\"Anteil gap<=5:  {near5/total:.3f}\")\n",
    "print(f\"Anteil gap<=10: {near10/total:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d1f4664-4953-4d1a-bd6d-94a6fa66f483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obergrenze (MST-Bottleneck, single-link): U = 0.600\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mst_bottleneck_abs(subX):\n",
    "    R = np.abs(subX.T @ subX)\n",
    "    np.fill_diagonal(R, 0.0)\n",
    "    m = R.shape[0]\n",
    "    used = np.zeros(m, dtype=bool); used[0] = True\n",
    "    best = R[0].copy(); best[0] = -np.inf\n",
    "    min_added = np.inf\n",
    "    for _ in range(m - 1):\n",
    "        j = np.argmax(best); w = best[j]\n",
    "        min_added = min(min_added, w)      # schwächste der hinzugefügten Kanten\n",
    "        used[j] = True\n",
    "        best = np.maximum(best, R[j])\n",
    "        best[used] = -np.inf\n",
    "    return float(min_added)\n",
    "\n",
    "bottles = [mst_bottleneck_abs(X[:, np.sort(cl)]) for cl in LargerClusters if len(cl) >= 2]\n",
    "U = float(min(bottles)) if bottles else np.nan\n",
    "print(f\"Obergrenze (MST-Bottleneck, single-link): U = {U:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7989ab9-a402-46a5-bd51-d9dff40761a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho* (aus MST-Bottlenecks) = 0.600\n",
      "Alle Clumps verbunden bei rho*?              True\n",
      "Alle Clumps verbunden bei rho* + 1e-4?       False\n",
      "Alle Clumps verbunden bei rho* + 0.01?       False\n",
      "Kritischer Cluster (argmin) bricht bei +1e-4? True  (id=84, size=5)\n"
     ]
    }
   ],
   "source": [
    "def mst_bottleneck_abs(subX: np.ndarray) -> float:\n",
    "    R = np.abs(subX.T @ subX)\n",
    "    np.fill_diagonal(R, 0.0)\n",
    "    m = R.shape[0]\n",
    "    used = np.zeros(m, dtype=bool); used[0] = True\n",
    "    best = R[0].copy(); best[0] = -np.inf\n",
    "    bott = np.inf\n",
    "    for _ in range(m - 1):\n",
    "        j = int(best.argmax()); w = float(best[j])\n",
    "        bott = min(bott, w)\n",
    "        used[j] = True\n",
    "        best = np.maximum(best, R[j])\n",
    "        best[used] = -np.inf\n",
    "    return bott\n",
    "\n",
    "def connected_at(subX: np.ndarray, thr: float) -> bool:\n",
    "    R = np.abs(subX.T @ subX); np.fill_diagonal(R, 0.0)\n",
    "    A = R >= thr\n",
    "    m = A.shape[0]\n",
    "    seen = np.zeros(m, bool); seen[0] = True\n",
    "    stack = [0]\n",
    "    while stack:\n",
    "        i = stack.pop()\n",
    "        for j in np.where(A[i])[0]:\n",
    "            if not seen[j]:\n",
    "                seen[j] = True; stack.append(j)\n",
    "    return seen.all()\n",
    "\n",
    "# 1) Kritischen Wert bestimmen\n",
    "bott = []\n",
    "idxs = []\n",
    "for cl in LargerClusters:\n",
    "    idx = np.sort(np.asarray(cl, int))\n",
    "    if idx.size >= 2:\n",
    "        bott.append(mst_bottleneck_abs(X[:, idx]))\n",
    "        idxs.append(idx)\n",
    "\n",
    "bott = np.array(bott)\n",
    "rho_star = float(bott.min())\n",
    "kstar = int(bott.argmin())\n",
    "eps1 = 1e-4   # sehr kleine Erhöhung\n",
    "eps2 = 1e-2   # 0.01 zur Illustration\n",
    "\n",
    "# 2) „Zertifikat“ prüfen/ausgeben\n",
    "ok_rho   = all(connected_at(X[:, idx], rho_star)       for idx in idxs)\n",
    "ok_plus1 = all(connected_at(X[:, idx], rho_star+eps1)  for idx in idxs)\n",
    "ok_plus2 = all(connected_at(X[:, idx], rho_star+eps2)  for idx in idxs)\n",
    "break_k  = not connected_at(X[:, idxs[kstar]], rho_star+eps1)\n",
    "\n",
    "print(f\"rho* (aus MST-Bottlenecks) = {rho_star:.3f}\")\n",
    "print(f\"Alle Clumps verbunden bei rho*?              {ok_rho}\")\n",
    "print(f\"Alle Clumps verbunden bei rho* + 1e-4?       {ok_plus1}\")\n",
    "print(f\"Alle Clumps verbunden bei rho* + 0.01?       {ok_plus2}\")\n",
    "print(f\"Kritischer Cluster (argmin) bricht bei +1e-4? {break_k}  (id={kstar}, size={idxs[kstar].size})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7e879ad-59b4-4152-8946-99a3fcce0149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend: slope=-0.002219  |  Anteil nicht-steigend: 0.583 (1.0≈monoton fallend)\n"
     ]
    }
   ],
   "source": [
    "# Prüft kurz, ob Median(|r|) mit wachsender Index-Distanz Δ abnimmt\n",
    "D = defaultdict(list)\n",
    "for cl in LargerClusters:\n",
    "    idx = np.sort(np.asarray(cl, int)); m = idx.size\n",
    "    if m < 2: continue\n",
    "    R = np.abs(X[:, idx].T @ X[:, idx])\n",
    "    for i in range(m):\n",
    "        for j in range(i+1, m):\n",
    "            D[idx[j] - idx[i]].append(R[i, j])\n",
    "\n",
    "deltas = np.array(sorted(D))\n",
    "meds   = np.array([np.median(D[d]) for d in deltas])\n",
    "slope  = np.polyfit(deltas, meds, 1)[0]            # <0 erwartet, wenn abnehmend\n",
    "share  = np.mean(np.diff(meds) <= 1e-9)            # Anteil nicht-steigender Schritte\n",
    "print(f\"Trend: slope={slope:.6f}  |  Anteil nicht-steigend: {share:.3f} (1.0≈monoton fallend)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5a15cc1-9f74-42ad-a54f-94cf0f419d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacent neighbors |r|: {'n': 7296, 'median': 0.2734602248397994, 'mean': 0.33374660938222583, 'q95': 0.8611810993543245, 'share_ge_thr': 0.15474232456140352}\n",
      "Random pairs   |r|: {'n': 7296, 'median': 0.028928661253092985, 'mean': 0.038745994298872016, 'q95': 0.10419360605853026, 'share_ge_thr': 0.0005482456140350877}\n",
      "Difference in share ≥ 0.6: 0.154\n"
     ]
    }
   ],
   "source": [
    "#  check if due to LD neighboring SNPs are often highly correlated\n",
    "\n",
    "thr = 0.6  \n",
    "\n",
    "def summary(v):\n",
    "    return dict(\n",
    "        n=len(v),\n",
    "        median=float(np.median(v)),\n",
    "        mean=float(np.mean(v)),\n",
    "        q95=float(np.quantile(v, 0.95)),\n",
    "        share_ge_thr=float((v >= thr).mean())\n",
    "    )\n",
    "\n",
    "# 1) Direkt benachbarte SNPs im Indexraum: (i, i+1)\n",
    "r_adj = np.abs((X[:, :-1] * X[:, 1:]).sum(axis=0))\n",
    "s_adj = summary(r_adj)\n",
    "\n",
    "# 2) Baseline: gleich viele zufällige Paare (i, j) mit i != j\n",
    "rng = np.random.default_rng(0)\n",
    "K = len(r_adj)\n",
    "i = rng.integers(0, p, K)\n",
    "j = (i + rng.integers(1, p, K)) % p  # garantiert i != j\n",
    "r_rand = np.abs((X[:, i] * X[:, j]).sum(axis=0))\n",
    "s_rand = summary(r_rand)\n",
    "\n",
    "print(\"Adjacent neighbors |r|:\", s_adj)\n",
    "print(\"Random pairs   |r|:\", s_rand)\n",
    "print(f\"Difference in share ≥ {thr}: {s_adj['share_ge_thr'] - s_rand['share_ge_thr']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5974047f-5d2b-4c88-89a0-e20705ec0acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
