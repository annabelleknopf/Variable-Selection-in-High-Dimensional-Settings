{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca4b40ae",
   "metadata": {},
   "source": [
    "# Prep_Results_Sim1\n",
    "Dieses Notebook lädt die in `Results1/` (oder `CheckResults1/`) abgelegten Simulationsergebnisse\n",
    "aus **Sim1** und bereitet Aggregat- und Long-Form-Tabellen analog zum bereitgestellten R‑Skript auf.\n",
    "\n",
    "**Was entsteht:**\n",
    "- `df` (aggregierte Metriken pro (k, rho, Methode))\n",
    "- `df_mBIC`, `df_mBIC2`, `df_Runtime` (Long‑Format auf Instanzebene)\n",
    "- Wide-Tabellen via `pivot_table` analog zu `dcast(...)`:\n",
    "  - `tab_Better`, `tab_Better2`, `tab_Worse`, `tab_Worse2`\n",
    "  - `tabFP`, `tabFDR2`, `tabPower`, `tabPower2`\n",
    "  - `tab_m`, `tabsem`, `tab_m2`, `tabsem2`, `tab_runtime`\n",
    "  \n",
    "Alle Tabellen können optional als CSV gespeichert werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Anzeigeoptionen\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8336a1",
   "metadata": {},
   "source": [
    "## Konfiguration & Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a400e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Suchreihenfolge der Ergebnisordner\n",
    "RESULTS_DIRS = [\"Results1\", \"CheckResults1\"]\n",
    "RESULTS_DIR = next((d for d in RESULTS_DIRS if os.path.isdir(d)), RESULTS_DIRS[0])\n",
    "print(\"Nutze Ergebnisordner:\", RESULTS_DIR)\n",
    "\n",
    "# Szenario-Raster (nur für Ausgabe/Pivots; Dateien werden dynamisch gefunden)\n",
    "k_vec = [0, 5, 10, 20, 40]\n",
    "rho_vec = [0.0, 0.5, 0.8]\n",
    "\n",
    "# Schwelle wie im R-Code (numerische Toleranz)\n",
    "EPS = 1e-8\n",
    "\n",
    "def load_all_pickles(results_dir):\n",
    "    \"\"\"Lädt alle Pickle-Dateien 'Sim1.k_<k>.rho_<rho>.pkl' aus results_dir.\"\"\"\n",
    "    pattern = os.path.join(results_dir, \"Sim1.k_*.rho_*.pkl\")\n",
    "    files = sorted(glob.glob(pattern))\n",
    "    if not files:\n",
    "        print(\"Keine Dateien gefunden unter\", pattern)\n",
    "    items = []\n",
    "    for fn in files:\n",
    "        try:\n",
    "            with open(fn, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            # Extrahiere k und rho aus Dateinamen zur Sicherheit\n",
    "            base = os.path.basename(fn)\n",
    "            # Format: Sim1.k_<k>.rho_<rho>.pkl\n",
    "            k_str = base.split('k_')[1].split('.rho_')[0]\n",
    "            rho_str = base.split('rho_')[1].split('.pkl')[0]\n",
    "            k = int(k_str)\n",
    "            rho = float(rho_str)\n",
    "            data['k'] = int(data.get('k', k))\n",
    "            data['rho'] = float(data.get('rho', rho))\n",
    "            data['__file__'] = fn\n",
    "            items.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Laden von {fn}: {e}\")\n",
    "    return items\n",
    "\n",
    "def as_df_long_diff(diff_mat, method_names, instance_offset, scenario_id, value_name):\n",
    "    \"\"\"Formt eine (sim_nr x nr_methods)-Matrix in Long-Format mit Instance/Scenario um.\"\"\"\n",
    "    sim_nr, nr_methods = diff_mat.shape\n",
    "    df = pd.DataFrame(diff_mat, columns=method_names)\n",
    "    df['instance'] = np.arange(sim_nr) + instance_offset\n",
    "    df['scenario'] = scenario_id\n",
    "    long_df = df.melt(id_vars=['instance', 'scenario'], var_name='variable', value_name=value_name)\n",
    "    return long_df\n",
    "\n",
    "def sem_from_sd(sd, n):\n",
    "    return sd / np.sqrt(max(n, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06311e13",
   "metadata": {},
   "source": [
    "## Laden & Aufbereiten (analog R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840fd72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data = load_all_pickles(RESULTS_DIR)\n",
    "\n",
    "# Container für Aggregationen\n",
    "df_rows = []\n",
    "df_mBIC_list = []\n",
    "df_mBIC2_list = []\n",
    "df_Runtime_list = []\n",
    "\n",
    "instance_offset = 0\n",
    "scenario_id = 0\n",
    "\n",
    "for block in all_data:\n",
    "    mBIC_results  = np.asarray(block['mBIC_results'])\n",
    "    mBIC2_results = np.asarray(block['mBIC2_results'])\n",
    "    mBIC_FP       = np.asarray(block['mBIC_FP'])\n",
    "    mBIC2_FP      = np.asarray(block['mBIC2_FP'])\n",
    "    mBIC_TP       = np.asarray(block['mBIC_TP'])\n",
    "    mBIC2_TP      = np.asarray(block['mBIC2_TP'])\n",
    "    runtime       = np.asarray(block['runtime'])\n",
    "    method_names  = list(block['method_names'])\n",
    "    k = int(block['k'])\n",
    "    rho = float(block['rho'])\n",
    "    \n",
    "    sim_nr, nr_methods = mBIC_results.shape\n",
    "    # Baseline = erste Methode (stepwise_plain)\n",
    "    stepwise = mBIC_results[:, [0]]\n",
    "    stepwise2 = mBIC2_results[:, [0]]\n",
    "    \n",
    "    res  = mBIC_results  - stepwise      # Differenzen zu Baseline (mBIC)\n",
    "    res2 = mBIC2_results - stepwise2     # Differenzen zu Baseline (mBIC2)\n",
    "    \n",
    "    # Zähl- und Gütemaße analog R\n",
    "    Worse  = (res  >  EPS).sum(axis=0)\n",
    "    Better = (res  < -EPS).sum(axis=0)\n",
    "    Worse2 = (res2 >  EPS).sum(axis=0)\n",
    "    Better2= (res2 < -EPS).sum(axis=0)\n",
    "    \n",
    "    FP    = mBIC_FP.mean(axis=0)\n",
    "    TP    = mBIC_TP.mean(axis=0)\n",
    "    Power = (TP / k) if k > 0 else np.zeros_like(TP)\n",
    "    \n",
    "    FP2   = mBIC2_FP.mean(axis=0)\n",
    "    TP2   = mBIC2_TP.mean(axis=0)\n",
    "    Power2= (TP2 / k) if k > 0 else np.zeros_like(TP2)\n",
    "    \n",
    "    # FDR2 = mean over sims of FP/(FP+TP); hier: erst pro Sim, dann Mittelwert\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        fdr2_sim = mBIC2_FP / (mBIC2_FP + mBIC2_TP)\n",
    "        fdr2_sim = np.where(np.isnan(fdr2_sim), 0.0, fdr2_sim)\n",
    "    FDR2 = fdr2_sim.mean(axis=0)\n",
    "    \n",
    "    mean_mBIC  = res.mean(axis=0)\n",
    "    mean_mBIC2 = res2.mean(axis=0)\n",
    "    sd_mBIC    = res.std(axis=0, ddof=1)\n",
    "    sd_mBIC2   = res2.std(axis=0, ddof=1)\n",
    "    sem_mBIC   = sd_mBIC  / np.sqrt(sim_nr)\n",
    "    sem_mBIC2  = sd_mBIC2 / np.sqrt(sim_nr)\n",
    "    \n",
    "    Runtime = runtime.mean(axis=0)\n",
    "    \n",
    "    # Aggregierte Zeilen pro Methode\n",
    "    for l, mname in enumerate(method_names):\n",
    "        df_rows.append({\n",
    "            'k': k, 'rho': rho, 'method': mname,\n",
    "            'Better': int(Better[l]), 'Worse': int(Worse[l]),\n",
    "            'Power': float(Power[l]), 'FP': float(FP[l]),\n",
    "            'Better2': int(Better2[l]), 'Worse2': int(Worse2[l]),\n",
    "            'Power2': float(Power2[l]), 'FDR2': float(FDR2[l]),\n",
    "            'mean_mBIC': float(mean_mBIC[l]), 'sd_mBIC': float(sd_mBIC[l]), 'sem_mBIC': float(sem_mBIC[l]),\n",
    "            'mean_mBIC2': float(mean_mBIC2[l]), 'sd_mBIC2': float(sd_mBIC2[l]), 'sem_mBIC2': float(sem_mBIC2[l]),\n",
    "            'Runtime': float(Runtime[l]),\n",
    "        })\n",
    "    \n",
    "    # Long-Form (Differenzen relativ zur Baseline)\n",
    "    df_mBIC_list.append(as_df_long_diff(res, method_names, instance_offset, scenario_id, 'mBIC'))\n",
    "    df_mBIC2_list.append(as_df_long_diff(res2, method_names, instance_offset, scenario_id, 'mBIC2'))\n",
    "    \n",
    "    # Runtime in Long-Form\n",
    "    rt_df = pd.DataFrame(runtime, columns=method_names)\n",
    "    rt_df['instance'] = np.arange(sim_nr) + instance_offset\n",
    "    rt_df['scenario'] = scenario_id\n",
    "    runtime_long = rt_df.melt(id_vars=['instance','scenario'], var_name='variable', value_name='Runtime')\n",
    "    df_Runtime_list.append(runtime_long)\n",
    "    \n",
    "    # Fortschritt der Indizes\n",
    "    instance_offset += sim_nr\n",
    "    scenario_id += 1\n",
    "\n",
    "# Gesamtdatensätze\n",
    "df = pd.DataFrame(df_rows)\n",
    "df_mBIC  = pd.concat(df_mBIC_list, ignore_index=True) if df_mBIC_list else pd.DataFrame(columns=['instance','scenario','variable','mBIC'])\n",
    "df_mBIC2 = pd.concat(df_mBIC2_list, ignore_index=True) if df_mBIC2_list else pd.DataFrame(columns=['instance','scenario','variable','mBIC2'])\n",
    "df_Runtime = pd.concat(df_Runtime_list, ignore_index=True) if df_Runtime_list else pd.DataFrame(columns=['instance','scenario','variable','Runtime'])\n",
    "\n",
    "# Faktoren/Sortierung analog R (Methodenreihenfolge wie aus Dateien)\n",
    "if not df.empty:\n",
    "    # method ordering per scenario may vary; take union in first-seen order\n",
    "    method_order = []\n",
    "    for block in all_data:\n",
    "        for m in block['method_names']:\n",
    "            if m not in method_order:\n",
    "                method_order.append(m)\n",
    "    df['method'] = pd.Categorical(df['method'], categories=method_order, ordered=True)\n",
    "\n",
    "# Typen angleichen\n",
    "for col in ['instance','scenario']:\n",
    "    if col in df_mBIC.columns:\n",
    "        df_mBIC[col] = df_mBIC[col].astype('category')\n",
    "    if col in df_mBIC2.columns:\n",
    "        df_mBIC2[col] = df_mBIC2[col].astype('category')\n",
    "    if col in df_Runtime.columns:\n",
    "        df_Runtime[col] = df_Runtime[col].astype('category')\n",
    "\n",
    "print(\"Fertig geladen. df shape:\", df.shape)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd632b0",
   "metadata": {},
   "source": [
    "## Wide‑Tabellen (analog `dcast`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79872b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hilfsfunktion für Pivots\n",
    "def dcast_like(data, value_col, drop_methods=None):\n",
    "    temp = data.copy()\n",
    "    if drop_methods is not None and 'method' in temp.columns:\n",
    "        temp = temp[~temp['method'].isin(drop_methods)]\n",
    "    pt = temp.pivot_table(index=['k','rho'], columns='method', values=value_col, aggfunc='first').reset_index()\n",
    "    # Spalten sortieren: k, rho, dann Methoden\n",
    "    cols = ['k','rho'] + [c for c in pt.columns if c not in ('k','rho')]\n",
    "    return pt[cols]\n",
    "\n",
    "drop_stepwise = ['stepwise_plain']  # wie im R-Code\n",
    "\n",
    "tab_Better  = dcast_like(df, 'Better',  drop_methods=drop_stepwise)\n",
    "tab_Better2 = dcast_like(df, 'Better2', drop_methods=drop_stepwise)\n",
    "tab_Worse   = dcast_like(df, 'Worse',   drop_methods=drop_stepwise)\n",
    "tab_Worse2  = dcast_like(df, 'Worse2',  drop_methods=drop_stepwise)\n",
    "tabFP       = dcast_like(df, 'FP')\n",
    "tabFDR2     = dcast_like(df, 'FDR2')\n",
    "\n",
    "# Power-Tabellen nur für k>0\n",
    "df_posk = df[df['k'] > 0] if not df.empty else df\n",
    "tabPower  = dcast_like(df_posk, 'Power')\n",
    "tabPower2 = dcast_like(df_posk, 'Power2')\n",
    "\n",
    "tab_m     = dcast_like(df, 'mean_mBIC')\n",
    "tabsem    = dcast_like(df, 'sem_mBIC')\n",
    "tab_m2    = dcast_like(df, 'mean_mBIC2')\n",
    "tabsem2   = dcast_like(df, 'sem_mBIC2')\n",
    "tab_runtime = dcast_like(df, 'Runtime')\n",
    "\n",
    "tab_Better.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db53e706",
   "metadata": {},
   "source": [
    "## (Optional) CSV‑Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ff7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OUT_DIR = os.path.join(RESULTS_DIR, \"Prepared\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def save_csv(df, name):\n",
    "    fn = os.path.join(OUT_DIR, f\"{name}.csv\")\n",
    "    df.to_csv(fn, index=False)\n",
    "    print(\"Gespeichert:\", fn)\n",
    "\n",
    "save_csv(df, \"df_aggregate\")\n",
    "save_csv(df_mBIC, \"df_mBIC_long\")\n",
    "save_csv(df_mBIC2, \"df_mBIC2_long\")\n",
    "save_csv(df_Runtime, \"df_Runtime_long\")\n",
    "\n",
    "save_csv(tab_Better, \"tab_Better\")\n",
    "save_csv(tab_Better2, \"tab_Better2\")\n",
    "save_csv(tab_Worse, \"tab_Worse\")\n",
    "save_csv(tab_Worse2, \"tab_Worse2\")\n",
    "save_csv(tabFP, \"tabFP\")\n",
    "save_csv(tabFDR2, \"tabFDR2\")\n",
    "save_csv(tabPower, \"tabPower\")\n",
    "save_csv(tabPower2, \"tabPower2\")\n",
    "save_csv(tab_m, \"tab_m\")\n",
    "save_csv(tabsem, \"tabsem\")\n",
    "save_csv(tab_m2, \"tab_m2\")\n",
    "save_csv(tabsem2, \"tabsem2\")\n",
    "save_csv(tab_runtime, \"tab_runtime\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745440a8",
   "metadata": {},
   "source": [
    "## Vorschau einiger Tabellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffcfd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(df.head(20))\n",
    "display(tab_Better.head(10))\n",
    "display(tab_m.head(10))\n",
    "display(tab_runtime.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
